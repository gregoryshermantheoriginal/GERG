{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gregoryshermantheoriginal/GERG/blob/main/LPD_CP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWCFcxk5JETG"
      },
      "source": [
        "#Initialise libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mC_dvBCHdRMy"
      },
      "outputs": [],
      "source": [
        "#Download Pytorch Geometric\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sCLg23JyhbWK"
      },
      "outputs": [],
      "source": [
        "#Import the libraries\n",
        "import os\n",
        "import torch\n",
        "import torch_geometric.datasets as datasets\n",
        "import torch_geometric.data as data\n",
        "import torch_geometric.transforms as transforms\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx\n",
        "\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from itertools import combinations, groupby\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from scipy.ndimage.filters import gaussian_filter1d\n",
        "from collections import namedtuple\n",
        "\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Flatten\n",
        "\n",
        "import sklearn\n",
        "import torch.nn.utils.prune as prune\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iol_MstdEoqf"
      },
      "source": [
        "#Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uClRU_UJLRw0"
      },
      "outputs": [],
      "source": [
        "#Set seed \n",
        "np.random.seed(1234)\n",
        "\n",
        "#Generate a random NetworkX graph\n",
        "def gnp_random_connected_graph(n, p):\n",
        "    \"\"\"\n",
        "    Generates a random undirected graph, similarly to an Erdős-Rényi \n",
        "    graph, but enforcing that the resulting graph is conneted\n",
        "    \"\"\"\n",
        "    edges = combinations(range(n), 2)\n",
        "    G = nx.Graph()\n",
        "    G.add_nodes_from(range(n))\n",
        "    if p <= 0:\n",
        "        return G\n",
        "    if p >= 1:\n",
        "        return nx.complete_graph(n, create_using=G)\n",
        "    for _, node_edges in groupby(edges, key=lambda x: x[0]):\n",
        "        node_edges = list(node_edges)\n",
        "        random_edge = random.choice(node_edges)\n",
        "        G.add_edge(*random_edge)\n",
        "        for e in node_edges:\n",
        "            if random.random() < p:\n",
        "                G.add_edge(*e)\n",
        "    return G\n",
        "\n",
        "    #Reference [1]: https://stackoverflow.com/questions/61958360/how-to-create-random-graph-where-each-node-has-at-least-1-edge-using-networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8ZHYDQHgLNxY"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1234)\n",
        "\n",
        "#Create 200 graphs with 5 nodes\n",
        "for i in range(1, 200):\n",
        "  j = 0\n",
        "  # j = j/10\n",
        "  k = random.randint(1,42)\n",
        "  globals()['G_'+str(i)] = gnp_random_connected_graph(5, j) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Yyd_ItECRMWn"
      },
      "outputs": [],
      "source": [
        "#Define node attributes\n",
        "#Randomise x and y coordinates for each of the 5 nodes\n",
        "np.random.seed(1234)\n",
        "\n",
        "\n",
        "for i in range(1,200):\n",
        "\n",
        "  x_cord_0 =  random.randint(50,60)\n",
        "  x_cord_1 = random.randint(45,50)\n",
        "  x_cord_2 = random.randint(40,50)\n",
        "  x_cord_3 = random.randint(10,20)\n",
        "  x_cord_4 = random.randint(10,20)\n",
        "  \n",
        "  y_cord_0 = random.randint(60,70)\n",
        "  y_cord_1 = random.randint(40,50)\n",
        "  y_cord_2 = random.randint(50,60)\n",
        "  y_cord_3 = random.randint(60,70)\n",
        "  y_cord_4 = random.randint(45,50)\n",
        "\n",
        "#Set node attributes\n",
        "  pos_x={0:x_cord_0, 1:x_cord_1, 2 :x_cord_2, 3 :x_cord_3, 4:x_cord_4}\n",
        "  pos_y= {0:y_cord_0, 1:y_cord_1, 2 :y_cord_2, 3 :y_cord_3, 4:y_cord_4}\n",
        "  nx.set_node_attributes(globals()['G_'+str(i)], pos_x, 'pos_x')\n",
        "  nx.set_node_attributes(globals()['G_'+str(i)], pos_y, 'pos_y')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XOnrUPFIsufW"
      },
      "outputs": [],
      "source": [
        "#Visualise a graph\n",
        "def viz(G):\n",
        "  fig, ax = plt.subplots(figsize = (15,8))\n",
        "  initialpos = {0:(nx.get_node_attributes(G, \"pos_x\")[0], nx.get_node_attributes(G, \"pos_y\")[0]), 1:(nx.get_node_attributes(G, \"pos_x\")[1], nx.get_node_attributes(G, \"pos_y\")[1]), \n",
        "                2:(nx.get_node_attributes(G, \"pos_x\")[2], nx.get_node_attributes(G, \"pos_y\")[2]), 3:(nx.get_node_attributes(G, \"pos_x\")[3], nx.get_node_attributes(G, \"pos_y\")[3]), \n",
        "                4:(nx.get_node_attributes(G, \"pos_x\")[4], nx.get_node_attributes(G, \"pos_y\")[4])}\n",
        "  nx.draw(G, with_labels = True, pos = initialpos)\n",
        "  limits=plt.axis('on') # turns on axis\n",
        "  ax.set_xlim(0,120)\n",
        "  ax.set_ylim(0,120)\n",
        "  ax.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wqrCr3d_t1uZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "34ffc637-ffdd-49d9-e5a2-ae7663ed12d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Visualise graph\n",
        "viz(G_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5JL6fLwEvQI"
      },
      "source": [
        "##MAST formulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nUrx1mFGVG4-"
      },
      "outputs": [],
      "source": [
        "#Adding connections based on the smallest distance(area) between nodes\n",
        "list_1 = [0,1,2,3,4]\n",
        "list_2 = [0,1,2,3,4]\n",
        "\n",
        "def graph_dataset(G): \n",
        "  edge_1 = []\n",
        "  edge_2 = []\n",
        "  distance = []\n",
        "  for u in list_1:\n",
        "    for v in list_2:\n",
        "      df = pd.DataFrame(columns = ['edge_1','edge_2', 'distance'])\n",
        "      if(u!=v):\n",
        "        dist = round((((nx.get_node_attributes(G, 'pos_x')[u]  - nx.get_node_attributes(G, 'pos_x')[v])**2 + (nx.get_node_attributes(G, 'pos_y')[u] - nx.get_node_attributes(G, 'pos_y')[v])**2)**0.5),2)\n",
        "        # x = random.randint(0, 5)\n",
        "        # dist = x + dist\n",
        "        edge_1.append(u)\n",
        "        edge_2.append(v)\n",
        "        distance.append(dist)\n",
        "        \n",
        "  df['edge_1'] = edge_1\n",
        "  df['edge_2'] = edge_2\n",
        "  df['distance'] = distance\n",
        "  df.drop(df[ (df['edge_1'] == 0) & (df['edge_2'] == 2)].index, inplace = True)\n",
        "  df.drop(df[ (df['edge_1'] == 0) & (df['edge_2'] == 3)].index, inplace = True)\n",
        "  df.drop(df[ (df['edge_1'] == 0) & (df['edge_2'] == 4)].index, inplace = True)\n",
        "  indexes = df[ (df['edge_1'] == 1) & (df['edge_2'] == 0)].index\n",
        "  df.drop(indexes, inplace = True)\n",
        "  indexes = df[ (df['edge_1'] == 1) & (df['edge_2'] == 3)].index\n",
        "  df.drop(indexes, inplace = True)\n",
        "  indexes = df[ (df['edge_1'] == 1) & (df['edge_2'] == 4)].index\n",
        "  df.drop(indexes, inplace = True)\n",
        "  indexes = df[ (df['edge_1'] == 2) & (df['edge_2'] == 0)].index\n",
        "  df.drop(indexes, inplace = True)\n",
        "  # indexes = df[ (df['edge_1'] == 2) & (df['edge_2'] == 3) ].index\n",
        "  # df.drop(indexes, inplace = True)\n",
        "  # df.drop(df[ (df['edge_1'] == 2) & (df['edge_2'] == 4)].index, inplace = True)\n",
        "  df.drop(df[ (df['edge_1'] == 2) & (df['edge_2'] == 1)].index, inplace = True)\n",
        "\n",
        "  df.sort_values(by = ['distance'], inplace = True)\n",
        "\n",
        "  min_df = pd.DataFrame() \n",
        "  for i in df.edge_1.unique():\n",
        "    globals()['df_'+str(i)] = df[df['edge_1'] == i]\n",
        "    globals()['df_'+str(i)] = globals()['df_'+str(i)][globals()['df_'+str(i)].distance == globals()['df_'+str(i)].distance.min()]\n",
        "    min_df = min_df.append(globals()['df_'+str(i)], ignore_index = True)\n",
        "  \n",
        "  return min_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G3tEzI_oTFws"
      },
      "outputs": [],
      "source": [
        "#Iterate the MAST function over the 200 graphs\n",
        "for i in range(1,200):\n",
        "  globals()['min_df_'+str(i)] = graph_dataset(globals()['G_'+str(i)])\n",
        "  globals()['min_df_'+str(i)].sort_values( by = ['edge_1'], inplace = True)\n",
        "  globals()['min_df_'+str(i)].reset_index (inplace = True)\n",
        "  globals()['min_df_'+str(i)].drop(columns = ['index'], inplace = True)\n",
        " \n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YF53zfq_QWHr"
      },
      "outputs": [],
      "source": [
        "#Further MAST formulation\n",
        "#Ensuring that the constraint is met, i.e. node x and node y can only be connected if and only if, coverage area of node x & coverage area of node y > distance between x and y\n",
        "for i in range(1, 200):\n",
        "    if((globals()['min_df_'+str(i)].iloc[0,0] == 0) & (globals()['min_df_'+str(i)].iloc[0,1] == 1)):\n",
        "      if(globals()['min_df_'+str(i)].iloc[0,2]>globals()['min_df_'+str(i)].iloc[1,2]): #0,1\n",
        "        globals()['min_df_'+str(i)].iloc[1,2] = globals()['min_df_'+str(i)].iloc[0,2]\n",
        "      else:\n",
        "        globals()['min_df_'+str(i)].iloc[0,2] = globals()['min_df_'+str(i)].iloc[1,2]\n",
        "    if((globals()['min_df_'+str(i)].iloc[2,0] == 2) & (globals()['min_df_'+str(i)].iloc[2,1] == 3)): #2,3\n",
        "      if(globals()['min_df_'+str(i)].iloc[2,2]>globals()['min_df_'+str(i)].iloc[3,2]):\n",
        "        globals()['min_df_'+str(i)].iloc[3,2] = globals()['min_df_'+str(i)].iloc[2,2]\n",
        "      else:\n",
        "        globals()['min_df_'+str(i)].iloc[2,2] = globals()['min_df_'+str(i)].iloc[3,2]\n",
        "    if((globals()['min_df_'+str(i)].iloc[2,0] == 2) & (globals()['min_df_'+str(i)].iloc[2,1] == 4)): #2,4\n",
        "      if(globals()['min_df_'+str(i)].iloc[2,2]>globals()['min_df_'+str(i)].iloc[4,2]):\n",
        "        globals()['min_df_'+str(i)].iloc[4,2] = globals()['min_df_'+str(i)].iloc[2,2]\n",
        "      else:\n",
        "        globals()['min_df_'+str(i)].iloc[2,2] =globals()['min_df_'+str(i)].iloc[4,2]\n",
        "  \n",
        "    \n",
        "  \n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qeMiwsb8Ry4O"
      },
      "outputs": [],
      "source": [
        "#Set coverage area as a node attribute for the nodes\n",
        "for i in range(1,200):\n",
        "  pow={}\n",
        "  pow={0:globals()['min_df_'+str(i)]['distance'][0], 1:globals()['min_df_'+str(i)]['distance'][1], 2:globals()['min_df_'+str(i)]['distance'][2], 3:globals()['min_df_'+str(i)]['distance'][3], 4:globals()['min_df_'+str(i)]['distance'][4]}\n",
        "  nx.set_node_attributes(globals()['G_'+str(i)], pow, 'y')\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0qOD9gT5UJwr"
      },
      "outputs": [],
      "source": [
        "#Adding edges where the constraint is met, i.e. edge exist between a pair of nodes if and only if their individual coverage area is greater than the distance between the pair of nodes\n",
        "for i in range(1,200):\n",
        "  globals()['G_'+str(i)].add_edge(0, 1)\n",
        "  cov_0 = nx.get_node_attributes(globals()['G_'+str(i)], 'y')[0]\n",
        "  cov_1 = nx.get_node_attributes(globals()['G_'+str(i)], 'y')[1]\n",
        "  cov_2 = nx.get_node_attributes(globals()['G_'+str(i)], 'y')[2]\n",
        "  cov_3 = nx.get_node_attributes(globals()['G_'+str(i)], 'y')[3]\n",
        "  cov_4 = nx.get_node_attributes(globals()['G_'+str(i)], 'y')[4]\n",
        "  dist_12 = round((((nx.get_node_attributes(globals()['G_'+str(i)], 'pos_x')[1]  - nx.get_node_attributes(globals()['G_'+str(i)], 'pos_x')[2])**2 + (nx.get_node_attributes(globals()['G_'+str(i)], 'pos_y')[1] - nx.get_node_attributes(globals()['G_'+str(i)], 'pos_y')[2])**2)**0.5),2)\n",
        "  dist_23 = round((((nx.get_node_attributes(globals()['G_'+str(i)], 'pos_x')[2]  - nx.get_node_attributes(globals()['G_'+str(i)], 'pos_x')[3])**2 + (nx.get_node_attributes(globals()['G_'+str(i)], 'pos_y')[2] - nx.get_node_attributes(globals()['G_'+str(i)], 'pos_y')[3])**2)**0.5),2)\n",
        "  dist_24 = round((((nx.get_node_attributes(globals()['G_'+str(i)], 'pos_x')[2]  - nx.get_node_attributes(globals()['G_'+str(i)], 'pos_x')[4])**2 + (nx.get_node_attributes(globals()['G_'+str(i)], 'pos_y')[2] - nx.get_node_attributes(globals()['G_'+str(i)], 'pos_y')[4])**2)**0.5),2)\n",
        "  dist_34 = round((((nx.get_node_attributes(globals()['G_'+str(i)], 'pos_x')[3]  - nx.get_node_attributes(globals()['G_'+str(i)], 'pos_x')[4])**2 + (nx.get_node_attributes(globals()['G_'+str(i)], 'pos_y')[3] - nx.get_node_attributes(globals()['G_'+str(i)], 'pos_y')[4])**2)**0.5),2)\n",
        "  if((cov_1 >= dist_12) & (cov_2 >= dist_12)):\n",
        "    globals()['G_'+str(i)].add_edge(1, 2)\n",
        "  if((cov_2>=dist_23) & (cov_3>=dist_23)):\n",
        "    globals()['G_'+str(i)].add_edge(2, 3)  \n",
        "  if((cov_2>=dist_24) & (cov_4>=dist_24)):\n",
        "    globals()['G_'+str(i)].add_edge(2, 4)  \n",
        "  if((cov_3>=dist_34) & (cov_4>=dist_34)):\n",
        "    globals()['G_'+str(i)].add_edge(3, 4)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv5tDt1LHgNU"
      },
      "source": [
        "##Converting NetworkX graph to Pytorch Geometric Objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bcrQaCPcEJDI"
      },
      "outputs": [],
      "source": [
        "#Appeding all the graphs to an empty list\n",
        "Graphs = []\n",
        "for i in range(1, 200):\n",
        "  Graphs.append(globals()['G_'+str(i)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QW5IVA9JkWXa"
      },
      "outputs": [],
      "source": [
        "#Convert to PyG objects with features as node coordinates\n",
        "for i in range(1,199):\n",
        "  globals()['data_'+str(i)] = from_networkx(Graphs[i],['pos_x','pos_y'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_o9vZWEarkPe"
      },
      "outputs": [],
      "source": [
        "#List of data for dataloader\n",
        "data_list = [data_1,\tdata_2,\tdata_3,\tdata_4,\tdata_5,\tdata_6,\tdata_7,\tdata_8,\tdata_9,\tdata_10,\tdata_11,\tdata_12,\tdata_13,\tdata_14,\tdata_15,\tdata_16,\tdata_17,\tdata_18,\tdata_19,\tdata_20,\tdata_21,\tdata_22,\tdata_23,\tdata_24,\tdata_25,\tdata_26,\tdata_27,\tdata_28,\tdata_29,\tdata_30,\tdata_31,\tdata_32,\tdata_33,\tdata_34,\tdata_35,\tdata_36,\tdata_37,\tdata_38,\tdata_39,\tdata_40,\tdata_41,\tdata_42,\tdata_43,\tdata_44,\tdata_45,\tdata_46,\tdata_47,\tdata_48,\tdata_49,\tdata_50,\tdata_51,\tdata_52,\tdata_53,\tdata_54,\tdata_55,\tdata_56,\tdata_57,\tdata_58,\tdata_59,\tdata_60,\tdata_61,\tdata_62,\tdata_63,\tdata_64,\tdata_65,\tdata_66,\tdata_67,\tdata_68,\tdata_69,\tdata_70,\tdata_71,\tdata_72,\tdata_73,\tdata_74,\tdata_75,\tdata_76,\tdata_77,\tdata_78,\tdata_79,\tdata_80,\tdata_81,\tdata_82,\tdata_83,\tdata_84,\tdata_85,\tdata_86,\tdata_87,\tdata_88,\tdata_89,\tdata_90,\tdata_91,\tdata_92,\tdata_93,\tdata_94,\tdata_95,\tdata_96,\tdata_97,\tdata_98,\tdata_99,\tdata_100,\tdata_101,\tdata_102,\tdata_103,\tdata_104,\tdata_105,\tdata_106,\tdata_107,\tdata_108,\tdata_109,\tdata_110,\tdata_111,\tdata_112,\tdata_113,\tdata_114,\tdata_115,\tdata_116,\tdata_117,\tdata_118,\tdata_119,\tdata_120,\tdata_121,\tdata_122,\tdata_123,\tdata_124,\tdata_125,\tdata_126,\tdata_127,\tdata_128,\tdata_129,\tdata_130,\tdata_131,\tdata_132,\tdata_133,\tdata_134,\tdata_135,\tdata_136,\tdata_137,\tdata_138,\tdata_139,\tdata_140,\tdata_141,\tdata_142,\tdata_143,\tdata_144,\tdata_145,\tdata_146,\tdata_147,\tdata_148,\tdata_149,\tdata_150,\tdata_151,\tdata_152,\tdata_153,\tdata_154,\tdata_155,\tdata_156,\tdata_157,\tdata_158,\tdata_159,\tdata_160,\tdata_161,\tdata_162,\tdata_163,\tdata_164,\tdata_165,\tdata_166,\tdata_167,\tdata_168,\tdata_169,\tdata_170,\tdata_171,\tdata_172,\tdata_173,\tdata_174,\tdata_175,\tdata_176,\tdata_177,\tdata_178,\tdata_179,\tdata_180,\tdata_181,\tdata_182,\tdata_183,\tdata_184,\tdata_185,\tdata_186,\tdata_187,\tdata_188,\tdata_189,\tdata_190,\tdata_191,\tdata_192,\tdata_193,\tdata_194,\tdata_195,\tdata_196,\tdata_197,\tdata_198]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8ucv6M2jpDfT"
      },
      "outputs": [],
      "source": [
        "#Split data into train and test\n",
        "train_data = data_list[0:190]\n",
        "\n",
        "test_data = data_list[190:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "c7bMNKhtkW1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756c6d9b-3f01-418a-fafe-0b2622ed0ff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ],
      "source": [
        "#Prepare data before feeding into our GCN \n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj5N1bJm21CP"
      },
      "source": [
        "#GCN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxHPCFyPFF5G"
      },
      "source": [
        "##Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gHQGKDMZlYqW"
      },
      "outputs": [],
      "source": [
        "#GCN Architecture\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        \n",
        "        self.linear2 = torch.nn.Linear(2, 512)\n",
        "        self.conv2 = GCNConv(512,256)\n",
        "        self.conv3 = GCNConv(256,128)\n",
        "\n",
        "        self.conv4 = GCNConv(128,64)\n",
        "\n",
        "        \n",
        "        \n",
        "        self.linear1 = torch.nn.Linear(64,1)\n",
        "        #self.linear3 = torch.nn.Linear(32,1)\n",
        "    def forward(self, x, edge_index):\n",
        "       \n",
        "        x = self.linear2(x)\n",
        "        x = x.relu()\n",
        "        \n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        \n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "\n",
        "               \n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        \n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = x.relu()\n",
        "        \n",
        "\n",
        "        x = self.linear1(x)\n",
        "        x = x.relu()\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        \n",
        "               \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NuLyKWxi00Tb"
      },
      "outputs": [],
      "source": [
        "#Initialise our GCN model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN(512).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nrXA4svp1uyE"
      },
      "outputs": [],
      "source": [
        "#Define optimiser\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "O4DYs-DeLE6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0d9e20-bc71-4a36-fe0b-29e7f4c219d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (linear2): Linear(in_features=2, out_features=512, bias=True)\n",
            "  (conv2): GCNConv(512, 256)\n",
            "  (conv3): GCNConv(256, 128)\n",
            "  (conv4): GCNConv(128, 64)\n",
            "  (linear1): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Model architecture\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReqqJOxsFIwP"
      },
      "source": [
        "##Train our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WViLYFG_8Teo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ce29a2-3273-4297-9c82-5e5c4d5e3e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "tensor(45.1658, grad_fn=<MseLossBackward0>)\n",
            "1\n",
            "tensor(32.0682, grad_fn=<MseLossBackward0>)\n",
            "2\n",
            "tensor(45.7550, grad_fn=<MseLossBackward0>)\n",
            "3\n",
            "tensor(35.6354, grad_fn=<MseLossBackward0>)\n",
            "4\n",
            "tensor(37.6803, grad_fn=<MseLossBackward0>)\n",
            "5\n",
            "tensor(38.9692, grad_fn=<MseLossBackward0>)\n",
            "6\n",
            "tensor(32.4871, grad_fn=<MseLossBackward0>)\n",
            "7\n",
            "tensor(38.2033, grad_fn=<MseLossBackward0>)\n",
            "8\n",
            "tensor(34.4604, grad_fn=<MseLossBackward0>)\n",
            "9\n",
            "tensor(35.5760, grad_fn=<MseLossBackward0>)\n",
            "10\n",
            "tensor(35.5194, grad_fn=<MseLossBackward0>)\n",
            "11\n",
            "tensor(33.9318, grad_fn=<MseLossBackward0>)\n",
            "12\n",
            "tensor(36.3178, grad_fn=<MseLossBackward0>)\n",
            "13\n",
            "tensor(32.4887, grad_fn=<MseLossBackward0>)\n",
            "14\n",
            "tensor(36.4865, grad_fn=<MseLossBackward0>)\n",
            "15\n",
            "tensor(31.4074, grad_fn=<MseLossBackward0>)\n",
            "16\n",
            "tensor(33.4000, grad_fn=<MseLossBackward0>)\n",
            "17\n",
            "tensor(34.7904, grad_fn=<MseLossBackward0>)\n",
            "18\n",
            "tensor(30.8821, grad_fn=<MseLossBackward0>)\n",
            "19\n",
            "tensor(34.0807, grad_fn=<MseLossBackward0>)\n",
            "20\n",
            "tensor(30.8335, grad_fn=<MseLossBackward0>)\n",
            "21\n",
            "tensor(30.7628, grad_fn=<MseLossBackward0>)\n",
            "22\n",
            "tensor(32.4381, grad_fn=<MseLossBackward0>)\n",
            "23\n",
            "tensor(31.0855, grad_fn=<MseLossBackward0>)\n",
            "24\n",
            "tensor(29.0774, grad_fn=<MseLossBackward0>)\n",
            "25\n",
            "tensor(32.0013, grad_fn=<MseLossBackward0>)\n",
            "26\n",
            "tensor(28.5736, grad_fn=<MseLossBackward0>)\n",
            "27\n",
            "tensor(28.7449, grad_fn=<MseLossBackward0>)\n",
            "28\n",
            "tensor(30.8368, grad_fn=<MseLossBackward0>)\n",
            "29\n",
            "tensor(29.5175, grad_fn=<MseLossBackward0>)\n",
            "30\n",
            "tensor(24.2525, grad_fn=<MseLossBackward0>)\n",
            "31\n",
            "tensor(24.6752, grad_fn=<MseLossBackward0>)\n",
            "32\n",
            "tensor(23.7161, grad_fn=<MseLossBackward0>)\n",
            "33\n",
            "tensor(26.6065, grad_fn=<MseLossBackward0>)\n",
            "34\n",
            "tensor(24.5530, grad_fn=<MseLossBackward0>)\n",
            "35\n",
            "tensor(23.2093, grad_fn=<MseLossBackward0>)\n",
            "36\n",
            "tensor(20.0445, grad_fn=<MseLossBackward0>)\n",
            "37\n",
            "tensor(19.7981, grad_fn=<MseLossBackward0>)\n",
            "38\n",
            "tensor(16.9431, grad_fn=<MseLossBackward0>)\n",
            "39\n",
            "tensor(19.5549, grad_fn=<MseLossBackward0>)\n",
            "40\n",
            "tensor(20.9777, grad_fn=<MseLossBackward0>)\n",
            "41\n",
            "tensor(19.3565, grad_fn=<MseLossBackward0>)\n",
            "42\n",
            "tensor(17.3737, grad_fn=<MseLossBackward0>)\n",
            "43\n",
            "tensor(22.3842, grad_fn=<MseLossBackward0>)\n",
            "44\n",
            "tensor(21.5928, grad_fn=<MseLossBackward0>)\n",
            "45\n",
            "tensor(16.8350, grad_fn=<MseLossBackward0>)\n",
            "46\n",
            "tensor(16.5630, grad_fn=<MseLossBackward0>)\n",
            "47\n",
            "tensor(20.8892, grad_fn=<MseLossBackward0>)\n",
            "48\n",
            "tensor(18.8652, grad_fn=<MseLossBackward0>)\n",
            "49\n",
            "tensor(25.6526, grad_fn=<MseLossBackward0>)\n",
            "50\n",
            "tensor(16.8046, grad_fn=<MseLossBackward0>)\n",
            "51\n",
            "tensor(13.5244, grad_fn=<MseLossBackward0>)\n",
            "52\n",
            "tensor(13.9989, grad_fn=<MseLossBackward0>)\n",
            "53\n",
            "tensor(16.3720, grad_fn=<MseLossBackward0>)\n",
            "54\n",
            "tensor(16.1379, grad_fn=<MseLossBackward0>)\n",
            "55\n",
            "tensor(16.3997, grad_fn=<MseLossBackward0>)\n",
            "56\n",
            "tensor(20.3030, grad_fn=<MseLossBackward0>)\n",
            "57\n",
            "tensor(16.3512, grad_fn=<MseLossBackward0>)\n",
            "58\n",
            "tensor(14.1300, grad_fn=<MseLossBackward0>)\n",
            "59\n",
            "tensor(14.4877, grad_fn=<MseLossBackward0>)\n",
            "60\n",
            "tensor(10.6835, grad_fn=<MseLossBackward0>)\n",
            "61\n",
            "tensor(12.9771, grad_fn=<MseLossBackward0>)\n",
            "62\n",
            "tensor(14.6521, grad_fn=<MseLossBackward0>)\n",
            "63\n",
            "tensor(12.7360, grad_fn=<MseLossBackward0>)\n",
            "64\n",
            "tensor(13.2717, grad_fn=<MseLossBackward0>)\n",
            "65\n",
            "tensor(12.8000, grad_fn=<MseLossBackward0>)\n",
            "66\n",
            "tensor(13.2352, grad_fn=<MseLossBackward0>)\n",
            "67\n",
            "tensor(17.0130, grad_fn=<MseLossBackward0>)\n",
            "68\n",
            "tensor(14.0662, grad_fn=<MseLossBackward0>)\n",
            "69\n",
            "tensor(12.4350, grad_fn=<MseLossBackward0>)\n",
            "70\n",
            "tensor(11.7595, grad_fn=<MseLossBackward0>)\n",
            "71\n",
            "tensor(13.4159, grad_fn=<MseLossBackward0>)\n",
            "72\n",
            "tensor(12.0375, grad_fn=<MseLossBackward0>)\n",
            "73\n",
            "tensor(13.7566, grad_fn=<MseLossBackward0>)\n",
            "74\n",
            "tensor(9.3973, grad_fn=<MseLossBackward0>)\n",
            "75\n",
            "tensor(11.5524, grad_fn=<MseLossBackward0>)\n",
            "76\n",
            "tensor(13.6515, grad_fn=<MseLossBackward0>)\n",
            "77\n",
            "tensor(15.2310, grad_fn=<MseLossBackward0>)\n",
            "78\n",
            "tensor(17.1399, grad_fn=<MseLossBackward0>)\n",
            "79\n",
            "tensor(16.6376, grad_fn=<MseLossBackward0>)\n",
            "80\n",
            "tensor(11.5121, grad_fn=<MseLossBackward0>)\n",
            "81\n",
            "tensor(8.6244, grad_fn=<MseLossBackward0>)\n",
            "82\n",
            "tensor(9.4447, grad_fn=<MseLossBackward0>)\n",
            "83\n",
            "tensor(12.2255, grad_fn=<MseLossBackward0>)\n",
            "84\n",
            "tensor(14.8107, grad_fn=<MseLossBackward0>)\n",
            "85\n",
            "tensor(17.2595, grad_fn=<MseLossBackward0>)\n",
            "86\n",
            "tensor(16.7279, grad_fn=<MseLossBackward0>)\n",
            "87\n",
            "tensor(14.3308, grad_fn=<MseLossBackward0>)\n",
            "88\n",
            "tensor(11.9374, grad_fn=<MseLossBackward0>)\n",
            "89\n",
            "tensor(12.1162, grad_fn=<MseLossBackward0>)\n",
            "90\n",
            "tensor(12.4994, grad_fn=<MseLossBackward0>)\n",
            "91\n",
            "tensor(11.9707, grad_fn=<MseLossBackward0>)\n",
            "92\n",
            "tensor(16.5522, grad_fn=<MseLossBackward0>)\n",
            "93\n",
            "tensor(14.9736, grad_fn=<MseLossBackward0>)\n",
            "94\n",
            "tensor(14.7440, grad_fn=<MseLossBackward0>)\n",
            "95\n",
            "tensor(13.0255, grad_fn=<MseLossBackward0>)\n",
            "96\n",
            "tensor(17.5272, grad_fn=<MseLossBackward0>)\n",
            "97\n",
            "tensor(12.5539, grad_fn=<MseLossBackward0>)\n",
            "98\n",
            "tensor(11.8112, grad_fn=<MseLossBackward0>)\n",
            "99\n",
            "tensor(9.7801, grad_fn=<MseLossBackward0>)\n",
            "100\n",
            "tensor(15.1521, grad_fn=<MseLossBackward0>)\n",
            "101\n",
            "tensor(17.5865, grad_fn=<MseLossBackward0>)\n",
            "102\n",
            "tensor(11.6859, grad_fn=<MseLossBackward0>)\n",
            "103\n",
            "tensor(14.4297, grad_fn=<MseLossBackward0>)\n",
            "104\n",
            "tensor(17.4513, grad_fn=<MseLossBackward0>)\n",
            "105\n",
            "tensor(13.9259, grad_fn=<MseLossBackward0>)\n",
            "106\n",
            "tensor(10.1758, grad_fn=<MseLossBackward0>)\n",
            "107\n",
            "tensor(14.2920, grad_fn=<MseLossBackward0>)\n",
            "108\n",
            "tensor(16.4421, grad_fn=<MseLossBackward0>)\n",
            "109\n",
            "tensor(13.8751, grad_fn=<MseLossBackward0>)\n",
            "110\n",
            "tensor(12.3306, grad_fn=<MseLossBackward0>)\n",
            "111\n",
            "tensor(15.5830, grad_fn=<MseLossBackward0>)\n",
            "112\n",
            "tensor(14.5274, grad_fn=<MseLossBackward0>)\n",
            "113\n",
            "tensor(12.2457, grad_fn=<MseLossBackward0>)\n",
            "114\n",
            "tensor(11.3438, grad_fn=<MseLossBackward0>)\n",
            "115\n",
            "tensor(12.1227, grad_fn=<MseLossBackward0>)\n",
            "116\n",
            "tensor(16.9155, grad_fn=<MseLossBackward0>)\n",
            "117\n",
            "tensor(19.1267, grad_fn=<MseLossBackward0>)\n",
            "118\n",
            "tensor(15.5895, grad_fn=<MseLossBackward0>)\n",
            "119\n",
            "tensor(14.4846, grad_fn=<MseLossBackward0>)\n",
            "120\n",
            "tensor(12.0857, grad_fn=<MseLossBackward0>)\n",
            "121\n",
            "tensor(12.5051, grad_fn=<MseLossBackward0>)\n",
            "122\n",
            "tensor(16.5781, grad_fn=<MseLossBackward0>)\n",
            "123\n",
            "tensor(15.5812, grad_fn=<MseLossBackward0>)\n",
            "124\n",
            "tensor(9.9657, grad_fn=<MseLossBackward0>)\n",
            "125\n",
            "tensor(13.0402, grad_fn=<MseLossBackward0>)\n",
            "126\n",
            "tensor(14.1861, grad_fn=<MseLossBackward0>)\n",
            "127\n",
            "tensor(16.7689, grad_fn=<MseLossBackward0>)\n",
            "128\n",
            "tensor(13.3222, grad_fn=<MseLossBackward0>)\n",
            "129\n",
            "tensor(10.3750, grad_fn=<MseLossBackward0>)\n",
            "130\n",
            "tensor(9.2829, grad_fn=<MseLossBackward0>)\n",
            "131\n",
            "tensor(9.4093, grad_fn=<MseLossBackward0>)\n",
            "132\n",
            "tensor(10.2809, grad_fn=<MseLossBackward0>)\n",
            "133\n",
            "tensor(11.3511, grad_fn=<MseLossBackward0>)\n",
            "134\n",
            "tensor(10.3196, grad_fn=<MseLossBackward0>)\n",
            "135\n",
            "tensor(11.3341, grad_fn=<MseLossBackward0>)\n",
            "136\n",
            "tensor(10.9017, grad_fn=<MseLossBackward0>)\n",
            "137\n",
            "tensor(11.1660, grad_fn=<MseLossBackward0>)\n",
            "138\n",
            "tensor(13.3516, grad_fn=<MseLossBackward0>)\n",
            "139\n",
            "tensor(11.5905, grad_fn=<MseLossBackward0>)\n",
            "140\n",
            "tensor(12.4673, grad_fn=<MseLossBackward0>)\n",
            "141\n",
            "tensor(12.5959, grad_fn=<MseLossBackward0>)\n",
            "142\n",
            "tensor(14.9330, grad_fn=<MseLossBackward0>)\n",
            "143\n",
            "tensor(14.5803, grad_fn=<MseLossBackward0>)\n",
            "144\n",
            "tensor(16.7937, grad_fn=<MseLossBackward0>)\n",
            "145\n",
            "tensor(13.6915, grad_fn=<MseLossBackward0>)\n",
            "146\n",
            "tensor(13.1189, grad_fn=<MseLossBackward0>)\n",
            "147\n",
            "tensor(13.3998, grad_fn=<MseLossBackward0>)\n",
            "148\n",
            "tensor(12.0846, grad_fn=<MseLossBackward0>)\n",
            "149\n",
            "tensor(13.2636, grad_fn=<MseLossBackward0>)\n",
            "150\n",
            "tensor(18.1470, grad_fn=<MseLossBackward0>)\n",
            "151\n",
            "tensor(19.5167, grad_fn=<MseLossBackward0>)\n",
            "152\n",
            "tensor(19.0770, grad_fn=<MseLossBackward0>)\n",
            "153\n",
            "tensor(18.2521, grad_fn=<MseLossBackward0>)\n",
            "154\n",
            "tensor(16.4688, grad_fn=<MseLossBackward0>)\n",
            "155\n",
            "tensor(19.7446, grad_fn=<MseLossBackward0>)\n",
            "156\n",
            "tensor(18.8506, grad_fn=<MseLossBackward0>)\n",
            "157\n",
            "tensor(17.9718, grad_fn=<MseLossBackward0>)\n",
            "158\n",
            "tensor(22.4456, grad_fn=<MseLossBackward0>)\n",
            "159\n",
            "tensor(19.8971, grad_fn=<MseLossBackward0>)\n",
            "160\n",
            "tensor(19.9085, grad_fn=<MseLossBackward0>)\n",
            "161\n",
            "tensor(15.3788, grad_fn=<MseLossBackward0>)\n",
            "162\n",
            "tensor(17.5696, grad_fn=<MseLossBackward0>)\n",
            "163\n",
            "tensor(16.3183, grad_fn=<MseLossBackward0>)\n",
            "164\n",
            "tensor(15.3680, grad_fn=<MseLossBackward0>)\n",
            "165\n",
            "tensor(20.5708, grad_fn=<MseLossBackward0>)\n",
            "166\n",
            "tensor(18.6383, grad_fn=<MseLossBackward0>)\n",
            "167\n",
            "tensor(15.2435, grad_fn=<MseLossBackward0>)\n",
            "168\n",
            "tensor(18.1062, grad_fn=<MseLossBackward0>)\n",
            "169\n",
            "tensor(20.0527, grad_fn=<MseLossBackward0>)\n",
            "170\n",
            "tensor(20.7452, grad_fn=<MseLossBackward0>)\n",
            "171\n",
            "tensor(23.7492, grad_fn=<MseLossBackward0>)\n",
            "172\n",
            "tensor(20.2888, grad_fn=<MseLossBackward0>)\n",
            "173\n",
            "tensor(18.4998, grad_fn=<MseLossBackward0>)\n",
            "174\n",
            "tensor(17.7542, grad_fn=<MseLossBackward0>)\n",
            "175\n",
            "tensor(22.3630, grad_fn=<MseLossBackward0>)\n",
            "176\n",
            "tensor(18.9958, grad_fn=<MseLossBackward0>)\n",
            "177\n",
            "tensor(14.9056, grad_fn=<MseLossBackward0>)\n",
            "178\n",
            "tensor(18.7340, grad_fn=<MseLossBackward0>)\n",
            "179\n",
            "tensor(19.6857, grad_fn=<MseLossBackward0>)\n",
            "180\n",
            "tensor(18.9277, grad_fn=<MseLossBackward0>)\n",
            "181\n",
            "tensor(16.7547, grad_fn=<MseLossBackward0>)\n",
            "182\n",
            "tensor(19.1725, grad_fn=<MseLossBackward0>)\n",
            "183\n",
            "tensor(18.8734, grad_fn=<MseLossBackward0>)\n",
            "184\n",
            "tensor(18.2139, grad_fn=<MseLossBackward0>)\n",
            "185\n",
            "tensor(20.3757, grad_fn=<MseLossBackward0>)\n",
            "186\n",
            "tensor(18.0748, grad_fn=<MseLossBackward0>)\n",
            "187\n",
            "tensor(15.5165, grad_fn=<MseLossBackward0>)\n",
            "188\n",
            "tensor(16.5119, grad_fn=<MseLossBackward0>)\n",
            "189\n",
            "tensor(17.8486, grad_fn=<MseLossBackward0>)\n",
            "190\n",
            "tensor(17.1490, grad_fn=<MseLossBackward0>)\n",
            "191\n",
            "tensor(19.4294, grad_fn=<MseLossBackward0>)\n",
            "192\n",
            "tensor(21.9639, grad_fn=<MseLossBackward0>)\n",
            "193\n",
            "tensor(21.3999, grad_fn=<MseLossBackward0>)\n",
            "194\n",
            "tensor(18.9642, grad_fn=<MseLossBackward0>)\n",
            "195\n",
            "tensor(16.7159, grad_fn=<MseLossBackward0>)\n",
            "196\n",
            "tensor(16.2139, grad_fn=<MseLossBackward0>)\n",
            "197\n",
            "tensor(17.6280, grad_fn=<MseLossBackward0>)\n",
            "198\n",
            "tensor(16.0609, grad_fn=<MseLossBackward0>)\n",
            "199\n",
            "tensor(14.4630, grad_fn=<MseLossBackward0>)\n",
            "200\n",
            "tensor(15.5360, grad_fn=<MseLossBackward0>)\n",
            "201\n",
            "tensor(17.9433, grad_fn=<MseLossBackward0>)\n",
            "202\n",
            "tensor(17.2998, grad_fn=<MseLossBackward0>)\n",
            "203\n",
            "tensor(14.7991, grad_fn=<MseLossBackward0>)\n",
            "204\n",
            "tensor(17.7705, grad_fn=<MseLossBackward0>)\n",
            "205\n",
            "tensor(19.2800, grad_fn=<MseLossBackward0>)\n",
            "206\n",
            "tensor(20.2059, grad_fn=<MseLossBackward0>)\n",
            "207\n",
            "tensor(17.9289, grad_fn=<MseLossBackward0>)\n",
            "208\n",
            "tensor(17.3661, grad_fn=<MseLossBackward0>)\n",
            "209\n",
            "tensor(17.6675, grad_fn=<MseLossBackward0>)\n",
            "210\n",
            "tensor(17.3707, grad_fn=<MseLossBackward0>)\n",
            "211\n",
            "tensor(16.3638, grad_fn=<MseLossBackward0>)\n",
            "212\n",
            "tensor(17.6538, grad_fn=<MseLossBackward0>)\n",
            "213\n",
            "tensor(14.8858, grad_fn=<MseLossBackward0>)\n",
            "214\n",
            "tensor(14.3023, grad_fn=<MseLossBackward0>)\n",
            "215\n",
            "tensor(17.7019, grad_fn=<MseLossBackward0>)\n",
            "216\n",
            "tensor(17.6196, grad_fn=<MseLossBackward0>)\n",
            "217\n",
            "tensor(18.5731, grad_fn=<MseLossBackward0>)\n",
            "218\n",
            "tensor(17.8368, grad_fn=<MseLossBackward0>)\n",
            "219\n",
            "tensor(18.7098, grad_fn=<MseLossBackward0>)\n",
            "220\n",
            "tensor(18.1130, grad_fn=<MseLossBackward0>)\n",
            "221\n",
            "tensor(17.5368, grad_fn=<MseLossBackward0>)\n",
            "222\n",
            "tensor(18.1678, grad_fn=<MseLossBackward0>)\n",
            "223\n",
            "tensor(18.1035, grad_fn=<MseLossBackward0>)\n",
            "224\n",
            "tensor(20.3350, grad_fn=<MseLossBackward0>)\n",
            "225\n",
            "tensor(21.1462, grad_fn=<MseLossBackward0>)\n",
            "226\n",
            "tensor(21.0831, grad_fn=<MseLossBackward0>)\n",
            "227\n",
            "tensor(21.4523, grad_fn=<MseLossBackward0>)\n",
            "228\n",
            "tensor(19.7747, grad_fn=<MseLossBackward0>)\n",
            "229\n",
            "tensor(15.4248, grad_fn=<MseLossBackward0>)\n",
            "230\n",
            "tensor(14.5591, grad_fn=<MseLossBackward0>)\n",
            "231\n",
            "tensor(19.0346, grad_fn=<MseLossBackward0>)\n",
            "232\n",
            "tensor(16.8312, grad_fn=<MseLossBackward0>)\n",
            "233\n",
            "tensor(17.0312, grad_fn=<MseLossBackward0>)\n",
            "234\n",
            "tensor(17.7472, grad_fn=<MseLossBackward0>)\n",
            "235\n",
            "tensor(15.1042, grad_fn=<MseLossBackward0>)\n",
            "236\n",
            "tensor(17.3532, grad_fn=<MseLossBackward0>)\n",
            "237\n",
            "tensor(16.5371, grad_fn=<MseLossBackward0>)\n",
            "238\n",
            "tensor(18.4901, grad_fn=<MseLossBackward0>)\n",
            "239\n",
            "tensor(18.7871, grad_fn=<MseLossBackward0>)\n",
            "240\n",
            "tensor(19.7087, grad_fn=<MseLossBackward0>)\n",
            "241\n",
            "tensor(16.2157, grad_fn=<MseLossBackward0>)\n",
            "242\n",
            "tensor(19.4749, grad_fn=<MseLossBackward0>)\n",
            "243\n",
            "tensor(20.4421, grad_fn=<MseLossBackward0>)\n",
            "244\n",
            "tensor(18.7647, grad_fn=<MseLossBackward0>)\n",
            "245\n",
            "tensor(23.4018, grad_fn=<MseLossBackward0>)\n",
            "246\n",
            "tensor(19.0965, grad_fn=<MseLossBackward0>)\n",
            "247\n",
            "tensor(14.8417, grad_fn=<MseLossBackward0>)\n",
            "248\n",
            "tensor(16.1527, grad_fn=<MseLossBackward0>)\n",
            "249\n",
            "tensor(16.0588, grad_fn=<MseLossBackward0>)\n",
            "250\n",
            "tensor(16.9494, grad_fn=<MseLossBackward0>)\n",
            "251\n",
            "tensor(17.0183, grad_fn=<MseLossBackward0>)\n",
            "252\n",
            "tensor(16.8611, grad_fn=<MseLossBackward0>)\n",
            "253\n",
            "tensor(16.6316, grad_fn=<MseLossBackward0>)\n",
            "254\n",
            "tensor(15.4031, grad_fn=<MseLossBackward0>)\n",
            "255\n",
            "tensor(14.5281, grad_fn=<MseLossBackward0>)\n",
            "256\n",
            "tensor(16.7198, grad_fn=<MseLossBackward0>)\n",
            "257\n",
            "tensor(18.7480, grad_fn=<MseLossBackward0>)\n",
            "258\n",
            "tensor(15.9911, grad_fn=<MseLossBackward0>)\n",
            "259\n",
            "tensor(14.8638, grad_fn=<MseLossBackward0>)\n",
            "260\n",
            "tensor(15.3457, grad_fn=<MseLossBackward0>)\n",
            "261\n",
            "tensor(16.8976, grad_fn=<MseLossBackward0>)\n",
            "262\n",
            "tensor(16.7116, grad_fn=<MseLossBackward0>)\n",
            "263\n",
            "tensor(13.2380, grad_fn=<MseLossBackward0>)\n",
            "264\n",
            "tensor(16.1456, grad_fn=<MseLossBackward0>)\n",
            "265\n",
            "tensor(15.5428, grad_fn=<MseLossBackward0>)\n",
            "266\n",
            "tensor(15.0121, grad_fn=<MseLossBackward0>)\n",
            "267\n",
            "tensor(16.2135, grad_fn=<MseLossBackward0>)\n",
            "268\n",
            "tensor(14.8758, grad_fn=<MseLossBackward0>)\n",
            "269\n",
            "tensor(16.5921, grad_fn=<MseLossBackward0>)\n",
            "270\n",
            "tensor(17.7466, grad_fn=<MseLossBackward0>)\n",
            "271\n",
            "tensor(16.0216, grad_fn=<MseLossBackward0>)\n",
            "272\n",
            "tensor(17.1497, grad_fn=<MseLossBackward0>)\n",
            "273\n",
            "tensor(17.3515, grad_fn=<MseLossBackward0>)\n",
            "274\n",
            "tensor(14.8995, grad_fn=<MseLossBackward0>)\n",
            "275\n",
            "tensor(15.8108, grad_fn=<MseLossBackward0>)\n",
            "276\n",
            "tensor(13.0278, grad_fn=<MseLossBackward0>)\n",
            "277\n",
            "tensor(12.6214, grad_fn=<MseLossBackward0>)\n",
            "278\n",
            "tensor(14.8880, grad_fn=<MseLossBackward0>)\n",
            "279\n",
            "tensor(17.0261, grad_fn=<MseLossBackward0>)\n",
            "280\n",
            "tensor(16.1405, grad_fn=<MseLossBackward0>)\n",
            "281\n",
            "tensor(15.5319, grad_fn=<MseLossBackward0>)\n",
            "282\n",
            "tensor(17.3906, grad_fn=<MseLossBackward0>)\n",
            "283\n",
            "tensor(17.1663, grad_fn=<MseLossBackward0>)\n",
            "284\n",
            "tensor(17.3090, grad_fn=<MseLossBackward0>)\n",
            "285\n",
            "tensor(16.4592, grad_fn=<MseLossBackward0>)\n",
            "286\n",
            "tensor(20.8155, grad_fn=<MseLossBackward0>)\n",
            "287\n",
            "tensor(19.4678, grad_fn=<MseLossBackward0>)\n",
            "288\n",
            "tensor(23.9299, grad_fn=<MseLossBackward0>)\n",
            "289\n",
            "tensor(18.3354, grad_fn=<MseLossBackward0>)\n",
            "290\n",
            "tensor(17.1593, grad_fn=<MseLossBackward0>)\n",
            "291\n",
            "tensor(18.2185, grad_fn=<MseLossBackward0>)\n",
            "292\n",
            "tensor(16.7982, grad_fn=<MseLossBackward0>)\n",
            "293\n",
            "tensor(19.2977, grad_fn=<MseLossBackward0>)\n",
            "294\n",
            "tensor(22.2111, grad_fn=<MseLossBackward0>)\n",
            "295\n",
            "tensor(17.5183, grad_fn=<MseLossBackward0>)\n",
            "296\n",
            "tensor(18.2286, grad_fn=<MseLossBackward0>)\n",
            "297\n",
            "tensor(19.8520, grad_fn=<MseLossBackward0>)\n",
            "298\n",
            "tensor(15.9252, grad_fn=<MseLossBackward0>)\n",
            "299\n",
            "tensor(18.2187, grad_fn=<MseLossBackward0>)\n",
            "300\n",
            "tensor(16.7557, grad_fn=<MseLossBackward0>)\n",
            "301\n",
            "tensor(14.5112, grad_fn=<MseLossBackward0>)\n",
            "302\n",
            "tensor(16.8764, grad_fn=<MseLossBackward0>)\n",
            "303\n",
            "tensor(14.9992, grad_fn=<MseLossBackward0>)\n",
            "304\n",
            "tensor(16.9228, grad_fn=<MseLossBackward0>)\n",
            "305\n",
            "tensor(19.4345, grad_fn=<MseLossBackward0>)\n",
            "306\n",
            "tensor(20.9740, grad_fn=<MseLossBackward0>)\n",
            "307\n",
            "tensor(19.9504, grad_fn=<MseLossBackward0>)\n",
            "308\n",
            "tensor(24.4154, grad_fn=<MseLossBackward0>)\n",
            "309\n",
            "tensor(22.1492, grad_fn=<MseLossBackward0>)\n",
            "310\n",
            "tensor(16.6485, grad_fn=<MseLossBackward0>)\n",
            "311\n",
            "tensor(17.9346, grad_fn=<MseLossBackward0>)\n",
            "312\n",
            "tensor(19.6845, grad_fn=<MseLossBackward0>)\n",
            "313\n",
            "tensor(16.4897, grad_fn=<MseLossBackward0>)\n",
            "314\n",
            "tensor(16.7675, grad_fn=<MseLossBackward0>)\n",
            "315\n",
            "tensor(19.2844, grad_fn=<MseLossBackward0>)\n",
            "316\n",
            "tensor(17.7014, grad_fn=<MseLossBackward0>)\n",
            "317\n",
            "tensor(18.7133, grad_fn=<MseLossBackward0>)\n",
            "318\n",
            "tensor(20.4207, grad_fn=<MseLossBackward0>)\n",
            "319\n",
            "tensor(18.7166, grad_fn=<MseLossBackward0>)\n",
            "320\n",
            "tensor(18.1538, grad_fn=<MseLossBackward0>)\n",
            "321\n",
            "tensor(19.2836, grad_fn=<MseLossBackward0>)\n",
            "322\n",
            "tensor(19.0119, grad_fn=<MseLossBackward0>)\n",
            "323\n",
            "tensor(17.4269, grad_fn=<MseLossBackward0>)\n",
            "324\n",
            "tensor(14.0173, grad_fn=<MseLossBackward0>)\n",
            "325\n",
            "tensor(15.5613, grad_fn=<MseLossBackward0>)\n",
            "326\n",
            "tensor(16.3916, grad_fn=<MseLossBackward0>)\n",
            "327\n",
            "tensor(12.9638, grad_fn=<MseLossBackward0>)\n",
            "328\n",
            "tensor(14.2529, grad_fn=<MseLossBackward0>)\n",
            "329\n",
            "tensor(17.0522, grad_fn=<MseLossBackward0>)\n",
            "330\n",
            "tensor(18.3498, grad_fn=<MseLossBackward0>)\n",
            "331\n",
            "tensor(24.4371, grad_fn=<MseLossBackward0>)\n",
            "332\n",
            "tensor(23.8411, grad_fn=<MseLossBackward0>)\n",
            "333\n",
            "tensor(23.5913, grad_fn=<MseLossBackward0>)\n",
            "334\n",
            "tensor(22.7116, grad_fn=<MseLossBackward0>)\n",
            "335\n",
            "tensor(19.7584, grad_fn=<MseLossBackward0>)\n",
            "336\n",
            "tensor(18.5148, grad_fn=<MseLossBackward0>)\n",
            "337\n",
            "tensor(16.4097, grad_fn=<MseLossBackward0>)\n",
            "338\n",
            "tensor(14.0660, grad_fn=<MseLossBackward0>)\n",
            "339\n",
            "tensor(16.8321, grad_fn=<MseLossBackward0>)\n",
            "340\n",
            "tensor(20.1922, grad_fn=<MseLossBackward0>)\n",
            "341\n",
            "tensor(20.4925, grad_fn=<MseLossBackward0>)\n",
            "342\n",
            "tensor(16.2950, grad_fn=<MseLossBackward0>)\n",
            "343\n",
            "tensor(17.4684, grad_fn=<MseLossBackward0>)\n",
            "344\n",
            "tensor(18.5555, grad_fn=<MseLossBackward0>)\n",
            "345\n",
            "tensor(19.3787, grad_fn=<MseLossBackward0>)\n",
            "346\n",
            "tensor(16.7181, grad_fn=<MseLossBackward0>)\n",
            "347\n",
            "tensor(19.0913, grad_fn=<MseLossBackward0>)\n",
            "348\n",
            "tensor(19.0056, grad_fn=<MseLossBackward0>)\n",
            "349\n",
            "tensor(15.9226, grad_fn=<MseLossBackward0>)\n",
            "350\n",
            "tensor(16.9340, grad_fn=<MseLossBackward0>)\n",
            "351\n",
            "tensor(20.1597, grad_fn=<MseLossBackward0>)\n",
            "352\n",
            "tensor(22.1197, grad_fn=<MseLossBackward0>)\n",
            "353\n",
            "tensor(15.9206, grad_fn=<MseLossBackward0>)\n",
            "354\n",
            "tensor(18.0889, grad_fn=<MseLossBackward0>)\n",
            "355\n",
            "tensor(18.3704, grad_fn=<MseLossBackward0>)\n",
            "356\n",
            "tensor(16.3549, grad_fn=<MseLossBackward0>)\n",
            "357\n",
            "tensor(17.9072, grad_fn=<MseLossBackward0>)\n",
            "358\n",
            "tensor(18.4650, grad_fn=<MseLossBackward0>)\n",
            "359\n",
            "tensor(21.9219, grad_fn=<MseLossBackward0>)\n",
            "360\n",
            "tensor(19.5521, grad_fn=<MseLossBackward0>)\n",
            "361\n",
            "tensor(18.0949, grad_fn=<MseLossBackward0>)\n",
            "362\n",
            "tensor(19.5427, grad_fn=<MseLossBackward0>)\n",
            "363\n",
            "tensor(20.9625, grad_fn=<MseLossBackward0>)\n",
            "364\n",
            "tensor(18.0041, grad_fn=<MseLossBackward0>)\n",
            "365\n",
            "tensor(16.3978, grad_fn=<MseLossBackward0>)\n",
            "366\n",
            "tensor(21.6764, grad_fn=<MseLossBackward0>)\n",
            "367\n",
            "tensor(17.5239, grad_fn=<MseLossBackward0>)\n",
            "368\n",
            "tensor(15.7551, grad_fn=<MseLossBackward0>)\n",
            "369\n",
            "tensor(16.5373, grad_fn=<MseLossBackward0>)\n",
            "370\n",
            "tensor(18.4085, grad_fn=<MseLossBackward0>)\n",
            "371\n",
            "tensor(17.4787, grad_fn=<MseLossBackward0>)\n",
            "372\n",
            "tensor(19.8127, grad_fn=<MseLossBackward0>)\n",
            "373\n",
            "tensor(18.4094, grad_fn=<MseLossBackward0>)\n",
            "374\n",
            "tensor(22.4880, grad_fn=<MseLossBackward0>)\n",
            "375\n",
            "tensor(19.5814, grad_fn=<MseLossBackward0>)\n",
            "376\n",
            "tensor(15.6900, grad_fn=<MseLossBackward0>)\n",
            "377\n",
            "tensor(18.1225, grad_fn=<MseLossBackward0>)\n",
            "378\n",
            "tensor(17.1557, grad_fn=<MseLossBackward0>)\n",
            "379\n",
            "tensor(13.8308, grad_fn=<MseLossBackward0>)\n",
            "380\n",
            "tensor(15.8280, grad_fn=<MseLossBackward0>)\n",
            "381\n",
            "tensor(17.1508, grad_fn=<MseLossBackward0>)\n",
            "382\n",
            "tensor(15.3950, grad_fn=<MseLossBackward0>)\n",
            "383\n",
            "tensor(17.7672, grad_fn=<MseLossBackward0>)\n",
            "384\n",
            "tensor(16.6883, grad_fn=<MseLossBackward0>)\n",
            "385\n",
            "tensor(15.0528, grad_fn=<MseLossBackward0>)\n",
            "386\n",
            "tensor(15.3905, grad_fn=<MseLossBackward0>)\n",
            "387\n",
            "tensor(17.4578, grad_fn=<MseLossBackward0>)\n",
            "388\n",
            "tensor(16.8669, grad_fn=<MseLossBackward0>)\n",
            "389\n",
            "tensor(18.8361, grad_fn=<MseLossBackward0>)\n",
            "390\n",
            "tensor(18.5768, grad_fn=<MseLossBackward0>)\n",
            "391\n",
            "tensor(17.8160, grad_fn=<MseLossBackward0>)\n",
            "392\n",
            "tensor(17.6236, grad_fn=<MseLossBackward0>)\n",
            "393\n",
            "tensor(14.2640, grad_fn=<MseLossBackward0>)\n",
            "394\n",
            "tensor(16.7742, grad_fn=<MseLossBackward0>)\n",
            "395\n",
            "tensor(15.4131, grad_fn=<MseLossBackward0>)\n",
            "396\n",
            "tensor(15.5002, grad_fn=<MseLossBackward0>)\n",
            "397\n",
            "tensor(15.7133, grad_fn=<MseLossBackward0>)\n",
            "398\n",
            "tensor(16.9386, grad_fn=<MseLossBackward0>)\n",
            "399\n",
            "tensor(18.2921, grad_fn=<MseLossBackward0>)\n",
            "400\n",
            "tensor(18.2494, grad_fn=<MseLossBackward0>)\n",
            "401\n",
            "tensor(21.0103, grad_fn=<MseLossBackward0>)\n",
            "402\n",
            "tensor(15.8708, grad_fn=<MseLossBackward0>)\n",
            "403\n",
            "tensor(18.1585, grad_fn=<MseLossBackward0>)\n",
            "404\n",
            "tensor(17.7818, grad_fn=<MseLossBackward0>)\n",
            "405\n",
            "tensor(16.7043, grad_fn=<MseLossBackward0>)\n",
            "406\n",
            "tensor(14.5509, grad_fn=<MseLossBackward0>)\n",
            "407\n",
            "tensor(15.0635, grad_fn=<MseLossBackward0>)\n",
            "408\n",
            "tensor(17.1865, grad_fn=<MseLossBackward0>)\n",
            "409\n",
            "tensor(14.6150, grad_fn=<MseLossBackward0>)\n",
            "410\n",
            "tensor(17.5926, grad_fn=<MseLossBackward0>)\n",
            "411\n",
            "tensor(17.4441, grad_fn=<MseLossBackward0>)\n",
            "412\n",
            "tensor(15.0675, grad_fn=<MseLossBackward0>)\n",
            "413\n",
            "tensor(15.4840, grad_fn=<MseLossBackward0>)\n",
            "414\n",
            "tensor(19.6692, grad_fn=<MseLossBackward0>)\n",
            "415\n",
            "tensor(21.6562, grad_fn=<MseLossBackward0>)\n",
            "416\n",
            "tensor(22.3419, grad_fn=<MseLossBackward0>)\n",
            "417\n",
            "tensor(19.6196, grad_fn=<MseLossBackward0>)\n",
            "418\n",
            "tensor(17.2057, grad_fn=<MseLossBackward0>)\n",
            "419\n",
            "tensor(17.1233, grad_fn=<MseLossBackward0>)\n",
            "420\n",
            "tensor(15.9625, grad_fn=<MseLossBackward0>)\n",
            "421\n",
            "tensor(15.7642, grad_fn=<MseLossBackward0>)\n",
            "422\n",
            "tensor(18.0220, grad_fn=<MseLossBackward0>)\n",
            "423\n",
            "tensor(14.8695, grad_fn=<MseLossBackward0>)\n",
            "424\n",
            "tensor(16.2029, grad_fn=<MseLossBackward0>)\n",
            "425\n",
            "tensor(14.9214, grad_fn=<MseLossBackward0>)\n",
            "426\n",
            "tensor(16.2699, grad_fn=<MseLossBackward0>)\n",
            "427\n",
            "tensor(17.7175, grad_fn=<MseLossBackward0>)\n",
            "428\n",
            "tensor(18.2722, grad_fn=<MseLossBackward0>)\n",
            "429\n",
            "tensor(19.6325, grad_fn=<MseLossBackward0>)\n",
            "430\n",
            "tensor(16.8535, grad_fn=<MseLossBackward0>)\n",
            "431\n",
            "tensor(17.9196, grad_fn=<MseLossBackward0>)\n",
            "432\n",
            "tensor(17.6954, grad_fn=<MseLossBackward0>)\n",
            "433\n",
            "tensor(19.1852, grad_fn=<MseLossBackward0>)\n",
            "434\n",
            "tensor(16.1267, grad_fn=<MseLossBackward0>)\n",
            "435\n",
            "tensor(16.6614, grad_fn=<MseLossBackward0>)\n",
            "436\n",
            "tensor(15.5498, grad_fn=<MseLossBackward0>)\n",
            "437\n",
            "tensor(19.3252, grad_fn=<MseLossBackward0>)\n",
            "438\n",
            "tensor(19.4705, grad_fn=<MseLossBackward0>)\n",
            "439\n",
            "tensor(22.8392, grad_fn=<MseLossBackward0>)\n",
            "440\n",
            "tensor(20.4387, grad_fn=<MseLossBackward0>)\n",
            "441\n",
            "tensor(21.6794, grad_fn=<MseLossBackward0>)\n",
            "442\n",
            "tensor(22.3607, grad_fn=<MseLossBackward0>)\n",
            "443\n",
            "tensor(21.0956, grad_fn=<MseLossBackward0>)\n",
            "444\n",
            "tensor(21.5398, grad_fn=<MseLossBackward0>)\n",
            "445\n",
            "tensor(15.7503, grad_fn=<MseLossBackward0>)\n",
            "446\n",
            "tensor(18.5224, grad_fn=<MseLossBackward0>)\n",
            "447\n",
            "tensor(13.6327, grad_fn=<MseLossBackward0>)\n",
            "448\n",
            "tensor(14.6578, grad_fn=<MseLossBackward0>)\n",
            "449\n",
            "tensor(17.4606, grad_fn=<MseLossBackward0>)\n",
            "450\n",
            "tensor(20.9767, grad_fn=<MseLossBackward0>)\n",
            "451\n",
            "tensor(19.2557, grad_fn=<MseLossBackward0>)\n",
            "452\n",
            "tensor(23.2985, grad_fn=<MseLossBackward0>)\n",
            "453\n",
            "tensor(20.2542, grad_fn=<MseLossBackward0>)\n",
            "454\n",
            "tensor(17.8916, grad_fn=<MseLossBackward0>)\n",
            "455\n",
            "tensor(16.2109, grad_fn=<MseLossBackward0>)\n",
            "456\n",
            "tensor(18.1746, grad_fn=<MseLossBackward0>)\n",
            "457\n",
            "tensor(18.4929, grad_fn=<MseLossBackward0>)\n",
            "458\n",
            "tensor(15.1290, grad_fn=<MseLossBackward0>)\n",
            "459\n",
            "tensor(18.7021, grad_fn=<MseLossBackward0>)\n",
            "460\n",
            "tensor(22.7551, grad_fn=<MseLossBackward0>)\n",
            "461\n",
            "tensor(19.7066, grad_fn=<MseLossBackward0>)\n",
            "462\n",
            "tensor(21.4541, grad_fn=<MseLossBackward0>)\n",
            "463\n",
            "tensor(20.9059, grad_fn=<MseLossBackward0>)\n",
            "464\n",
            "tensor(18.2124, grad_fn=<MseLossBackward0>)\n",
            "465\n",
            "tensor(20.3622, grad_fn=<MseLossBackward0>)\n",
            "466\n",
            "tensor(15.1418, grad_fn=<MseLossBackward0>)\n",
            "467\n",
            "tensor(19.8471, grad_fn=<MseLossBackward0>)\n",
            "468\n",
            "tensor(16.7009, grad_fn=<MseLossBackward0>)\n",
            "469\n",
            "tensor(15.8590, grad_fn=<MseLossBackward0>)\n",
            "470\n",
            "tensor(15.2941, grad_fn=<MseLossBackward0>)\n",
            "471\n",
            "tensor(15.3948, grad_fn=<MseLossBackward0>)\n",
            "472\n",
            "tensor(17.7888, grad_fn=<MseLossBackward0>)\n",
            "473\n",
            "tensor(16.5177, grad_fn=<MseLossBackward0>)\n",
            "474\n",
            "tensor(16.9774, grad_fn=<MseLossBackward0>)\n",
            "475\n",
            "tensor(17.5235, grad_fn=<MseLossBackward0>)\n",
            "476\n",
            "tensor(14.3837, grad_fn=<MseLossBackward0>)\n",
            "477\n",
            "tensor(16.2432, grad_fn=<MseLossBackward0>)\n",
            "478\n",
            "tensor(15.3824, grad_fn=<MseLossBackward0>)\n",
            "479\n",
            "tensor(15.8257, grad_fn=<MseLossBackward0>)\n",
            "480\n",
            "tensor(16.3689, grad_fn=<MseLossBackward0>)\n",
            "481\n",
            "tensor(15.0038, grad_fn=<MseLossBackward0>)\n",
            "482\n",
            "tensor(16.7064, grad_fn=<MseLossBackward0>)\n",
            "483\n",
            "tensor(14.9492, grad_fn=<MseLossBackward0>)\n",
            "484\n",
            "tensor(16.5602, grad_fn=<MseLossBackward0>)\n",
            "485\n",
            "tensor(17.5564, grad_fn=<MseLossBackward0>)\n",
            "486\n",
            "tensor(15.9810, grad_fn=<MseLossBackward0>)\n",
            "487\n",
            "tensor(15.4163, grad_fn=<MseLossBackward0>)\n",
            "488\n",
            "tensor(18.4859, grad_fn=<MseLossBackward0>)\n",
            "489\n",
            "tensor(19.7205, grad_fn=<MseLossBackward0>)\n",
            "490\n",
            "tensor(18.7034, grad_fn=<MseLossBackward0>)\n",
            "491\n",
            "tensor(19.1225, grad_fn=<MseLossBackward0>)\n",
            "492\n",
            "tensor(18.2772, grad_fn=<MseLossBackward0>)\n",
            "493\n",
            "tensor(20.2090, grad_fn=<MseLossBackward0>)\n",
            "494\n",
            "tensor(17.6722, grad_fn=<MseLossBackward0>)\n",
            "495\n",
            "tensor(16.9693, grad_fn=<MseLossBackward0>)\n",
            "496\n",
            "tensor(17.9109, grad_fn=<MseLossBackward0>)\n",
            "497\n",
            "tensor(13.7175, grad_fn=<MseLossBackward0>)\n",
            "498\n",
            "tensor(18.2623, grad_fn=<MseLossBackward0>)\n",
            "499\n",
            "tensor(19.9979, grad_fn=<MseLossBackward0>)\n",
            "500\n",
            "tensor(15.2666, grad_fn=<MseLossBackward0>)\n",
            "501\n",
            "tensor(13.3831, grad_fn=<MseLossBackward0>)\n",
            "502\n",
            "tensor(16.1797, grad_fn=<MseLossBackward0>)\n",
            "503\n",
            "tensor(18.9864, grad_fn=<MseLossBackward0>)\n",
            "504\n",
            "tensor(19.6198, grad_fn=<MseLossBackward0>)\n",
            "505\n",
            "tensor(15.8654, grad_fn=<MseLossBackward0>)\n",
            "506\n",
            "tensor(17.4283, grad_fn=<MseLossBackward0>)\n",
            "507\n",
            "tensor(18.9516, grad_fn=<MseLossBackward0>)\n",
            "508\n",
            "tensor(18.9748, grad_fn=<MseLossBackward0>)\n",
            "509\n",
            "tensor(23.2636, grad_fn=<MseLossBackward0>)\n",
            "510\n",
            "tensor(14.2564, grad_fn=<MseLossBackward0>)\n",
            "511\n",
            "tensor(16.0824, grad_fn=<MseLossBackward0>)\n",
            "512\n",
            "tensor(18.1600, grad_fn=<MseLossBackward0>)\n",
            "513\n",
            "tensor(16.4742, grad_fn=<MseLossBackward0>)\n",
            "514\n",
            "tensor(17.0978, grad_fn=<MseLossBackward0>)\n",
            "515\n",
            "tensor(19.5563, grad_fn=<MseLossBackward0>)\n",
            "516\n",
            "tensor(15.3399, grad_fn=<MseLossBackward0>)\n",
            "517\n",
            "tensor(16.4975, grad_fn=<MseLossBackward0>)\n",
            "518\n",
            "tensor(18.1926, grad_fn=<MseLossBackward0>)\n",
            "519\n",
            "tensor(14.3366, grad_fn=<MseLossBackward0>)\n",
            "520\n",
            "tensor(18.0116, grad_fn=<MseLossBackward0>)\n",
            "521\n",
            "tensor(15.8069, grad_fn=<MseLossBackward0>)\n",
            "522\n",
            "tensor(16.4759, grad_fn=<MseLossBackward0>)\n",
            "523\n",
            "tensor(18.5751, grad_fn=<MseLossBackward0>)\n",
            "524\n",
            "tensor(17.1396, grad_fn=<MseLossBackward0>)\n",
            "525\n",
            "tensor(16.1602, grad_fn=<MseLossBackward0>)\n",
            "526\n",
            "tensor(18.0559, grad_fn=<MseLossBackward0>)\n",
            "527\n",
            "tensor(18.2141, grad_fn=<MseLossBackward0>)\n",
            "528\n",
            "tensor(18.9431, grad_fn=<MseLossBackward0>)\n",
            "529\n",
            "tensor(15.7811, grad_fn=<MseLossBackward0>)\n",
            "530\n",
            "tensor(15.4175, grad_fn=<MseLossBackward0>)\n",
            "531\n",
            "tensor(15.7830, grad_fn=<MseLossBackward0>)\n",
            "532\n",
            "tensor(15.0160, grad_fn=<MseLossBackward0>)\n",
            "533\n",
            "tensor(16.3469, grad_fn=<MseLossBackward0>)\n",
            "534\n",
            "tensor(17.4121, grad_fn=<MseLossBackward0>)\n",
            "535\n",
            "tensor(15.3158, grad_fn=<MseLossBackward0>)\n",
            "536\n",
            "tensor(16.2609, grad_fn=<MseLossBackward0>)\n",
            "537\n",
            "tensor(16.2359, grad_fn=<MseLossBackward0>)\n",
            "538\n",
            "tensor(15.7142, grad_fn=<MseLossBackward0>)\n",
            "539\n",
            "tensor(17.3194, grad_fn=<MseLossBackward0>)\n",
            "540\n",
            "tensor(14.3000, grad_fn=<MseLossBackward0>)\n",
            "541\n",
            "tensor(12.9267, grad_fn=<MseLossBackward0>)\n",
            "542\n",
            "tensor(12.8180, grad_fn=<MseLossBackward0>)\n",
            "543\n",
            "tensor(13.1500, grad_fn=<MseLossBackward0>)\n",
            "544\n",
            "tensor(16.7637, grad_fn=<MseLossBackward0>)\n",
            "545\n",
            "tensor(14.6249, grad_fn=<MseLossBackward0>)\n",
            "546\n",
            "tensor(13.5237, grad_fn=<MseLossBackward0>)\n",
            "547\n",
            "tensor(15.6260, grad_fn=<MseLossBackward0>)\n",
            "548\n",
            "tensor(14.4474, grad_fn=<MseLossBackward0>)\n",
            "549\n",
            "tensor(12.3706, grad_fn=<MseLossBackward0>)\n",
            "550\n",
            "tensor(14.1414, grad_fn=<MseLossBackward0>)\n",
            "551\n",
            "tensor(13.3138, grad_fn=<MseLossBackward0>)\n",
            "552\n",
            "tensor(14.8906, grad_fn=<MseLossBackward0>)\n",
            "553\n",
            "tensor(14.5677, grad_fn=<MseLossBackward0>)\n",
            "554\n",
            "tensor(16.6871, grad_fn=<MseLossBackward0>)\n",
            "555\n",
            "tensor(16.5169, grad_fn=<MseLossBackward0>)\n",
            "556\n",
            "tensor(15.4489, grad_fn=<MseLossBackward0>)\n",
            "557\n",
            "tensor(16.9833, grad_fn=<MseLossBackward0>)\n",
            "558\n",
            "tensor(15.9550, grad_fn=<MseLossBackward0>)\n",
            "559\n",
            "tensor(14.3767, grad_fn=<MseLossBackward0>)\n",
            "560\n",
            "tensor(15.1792, grad_fn=<MseLossBackward0>)\n",
            "561\n",
            "tensor(17.5917, grad_fn=<MseLossBackward0>)\n",
            "562\n",
            "tensor(18.4597, grad_fn=<MseLossBackward0>)\n",
            "563\n",
            "tensor(21.9642, grad_fn=<MseLossBackward0>)\n",
            "564\n",
            "tensor(18.6885, grad_fn=<MseLossBackward0>)\n",
            "565\n",
            "tensor(18.2402, grad_fn=<MseLossBackward0>)\n",
            "566\n",
            "tensor(14.5473, grad_fn=<MseLossBackward0>)\n",
            "567\n",
            "tensor(12.3711, grad_fn=<MseLossBackward0>)\n",
            "568\n",
            "tensor(13.6324, grad_fn=<MseLossBackward0>)\n",
            "569\n",
            "tensor(12.3755, grad_fn=<MseLossBackward0>)\n",
            "570\n",
            "tensor(13.9611, grad_fn=<MseLossBackward0>)\n",
            "571\n",
            "tensor(15.2212, grad_fn=<MseLossBackward0>)\n",
            "572\n",
            "tensor(17.7903, grad_fn=<MseLossBackward0>)\n",
            "573\n",
            "tensor(16.0162, grad_fn=<MseLossBackward0>)\n",
            "574\n",
            "tensor(19.4750, grad_fn=<MseLossBackward0>)\n",
            "575\n",
            "tensor(22.7129, grad_fn=<MseLossBackward0>)\n",
            "576\n",
            "tensor(19.9125, grad_fn=<MseLossBackward0>)\n",
            "577\n",
            "tensor(20.9233, grad_fn=<MseLossBackward0>)\n",
            "578\n",
            "tensor(19.7966, grad_fn=<MseLossBackward0>)\n",
            "579\n",
            "tensor(11.9379, grad_fn=<MseLossBackward0>)\n",
            "580\n",
            "tensor(15.2547, grad_fn=<MseLossBackward0>)\n",
            "581\n",
            "tensor(11.4702, grad_fn=<MseLossBackward0>)\n",
            "582\n",
            "tensor(13.0346, grad_fn=<MseLossBackward0>)\n",
            "583\n",
            "tensor(14.4063, grad_fn=<MseLossBackward0>)\n",
            "584\n",
            "tensor(15.3884, grad_fn=<MseLossBackward0>)\n",
            "585\n",
            "tensor(14.6336, grad_fn=<MseLossBackward0>)\n",
            "586\n",
            "tensor(14.6977, grad_fn=<MseLossBackward0>)\n",
            "587\n",
            "tensor(14.9889, grad_fn=<MseLossBackward0>)\n",
            "588\n",
            "tensor(14.9942, grad_fn=<MseLossBackward0>)\n",
            "589\n",
            "tensor(15.2679, grad_fn=<MseLossBackward0>)\n",
            "590\n",
            "tensor(14.6636, grad_fn=<MseLossBackward0>)\n",
            "591\n",
            "tensor(14.2840, grad_fn=<MseLossBackward0>)\n",
            "592\n",
            "tensor(15.6540, grad_fn=<MseLossBackward0>)\n",
            "593\n",
            "tensor(13.7773, grad_fn=<MseLossBackward0>)\n",
            "594\n",
            "tensor(14.3148, grad_fn=<MseLossBackward0>)\n",
            "595\n",
            "tensor(15.8433, grad_fn=<MseLossBackward0>)\n",
            "596\n",
            "tensor(14.9444, grad_fn=<MseLossBackward0>)\n",
            "597\n",
            "tensor(15.9247, grad_fn=<MseLossBackward0>)\n",
            "598\n",
            "tensor(15.3783, grad_fn=<MseLossBackward0>)\n",
            "599\n",
            "tensor(17.2130, grad_fn=<MseLossBackward0>)\n",
            "600\n",
            "tensor(17.9726, grad_fn=<MseLossBackward0>)\n",
            "601\n",
            "tensor(15.7451, grad_fn=<MseLossBackward0>)\n",
            "602\n",
            "tensor(16.6546, grad_fn=<MseLossBackward0>)\n",
            "603\n",
            "tensor(15.6365, grad_fn=<MseLossBackward0>)\n",
            "604\n",
            "tensor(13.7345, grad_fn=<MseLossBackward0>)\n",
            "605\n",
            "tensor(15.9553, grad_fn=<MseLossBackward0>)\n",
            "606\n",
            "tensor(14.7365, grad_fn=<MseLossBackward0>)\n",
            "607\n",
            "tensor(14.4185, grad_fn=<MseLossBackward0>)\n",
            "608\n",
            "tensor(12.6148, grad_fn=<MseLossBackward0>)\n",
            "609\n",
            "tensor(15.5547, grad_fn=<MseLossBackward0>)\n",
            "610\n",
            "tensor(12.1816, grad_fn=<MseLossBackward0>)\n",
            "611\n",
            "tensor(12.9954, grad_fn=<MseLossBackward0>)\n",
            "612\n",
            "tensor(12.4323, grad_fn=<MseLossBackward0>)\n",
            "613\n",
            "tensor(14.7418, grad_fn=<MseLossBackward0>)\n",
            "614\n",
            "tensor(17.4169, grad_fn=<MseLossBackward0>)\n",
            "615\n",
            "tensor(16.1472, grad_fn=<MseLossBackward0>)\n",
            "616\n",
            "tensor(16.7467, grad_fn=<MseLossBackward0>)\n",
            "617\n",
            "tensor(15.2045, grad_fn=<MseLossBackward0>)\n",
            "618\n",
            "tensor(14.8577, grad_fn=<MseLossBackward0>)\n",
            "619\n",
            "tensor(13.6452, grad_fn=<MseLossBackward0>)\n",
            "620\n",
            "tensor(14.0809, grad_fn=<MseLossBackward0>)\n",
            "621\n",
            "tensor(15.7120, grad_fn=<MseLossBackward0>)\n",
            "622\n",
            "tensor(15.2104, grad_fn=<MseLossBackward0>)\n",
            "623\n",
            "tensor(18.5729, grad_fn=<MseLossBackward0>)\n",
            "624\n",
            "tensor(17.0761, grad_fn=<MseLossBackward0>)\n",
            "625\n",
            "tensor(15.3174, grad_fn=<MseLossBackward0>)\n",
            "626\n",
            "tensor(14.9001, grad_fn=<MseLossBackward0>)\n",
            "627\n",
            "tensor(16.5448, grad_fn=<MseLossBackward0>)\n",
            "628\n",
            "tensor(15.7192, grad_fn=<MseLossBackward0>)\n",
            "629\n",
            "tensor(15.2476, grad_fn=<MseLossBackward0>)\n",
            "630\n",
            "tensor(14.5059, grad_fn=<MseLossBackward0>)\n",
            "631\n",
            "tensor(11.5092, grad_fn=<MseLossBackward0>)\n",
            "632\n",
            "tensor(13.1686, grad_fn=<MseLossBackward0>)\n",
            "633\n",
            "tensor(13.0941, grad_fn=<MseLossBackward0>)\n",
            "634\n",
            "tensor(14.0721, grad_fn=<MseLossBackward0>)\n",
            "635\n",
            "tensor(13.6584, grad_fn=<MseLossBackward0>)\n",
            "636\n",
            "tensor(15.2786, grad_fn=<MseLossBackward0>)\n",
            "637\n",
            "tensor(14.3203, grad_fn=<MseLossBackward0>)\n",
            "638\n",
            "tensor(15.3060, grad_fn=<MseLossBackward0>)\n",
            "639\n",
            "tensor(15.7019, grad_fn=<MseLossBackward0>)\n",
            "640\n",
            "tensor(15.9256, grad_fn=<MseLossBackward0>)\n",
            "641\n",
            "tensor(15.1137, grad_fn=<MseLossBackward0>)\n",
            "642\n",
            "tensor(15.3207, grad_fn=<MseLossBackward0>)\n",
            "643\n",
            "tensor(15.1828, grad_fn=<MseLossBackward0>)\n",
            "644\n",
            "tensor(17.5084, grad_fn=<MseLossBackward0>)\n",
            "645\n",
            "tensor(20.2750, grad_fn=<MseLossBackward0>)\n",
            "646\n",
            "tensor(15.2008, grad_fn=<MseLossBackward0>)\n",
            "647\n",
            "tensor(19.4283, grad_fn=<MseLossBackward0>)\n",
            "648\n",
            "tensor(16.3633, grad_fn=<MseLossBackward0>)\n",
            "649\n",
            "tensor(15.8052, grad_fn=<MseLossBackward0>)\n",
            "650\n",
            "tensor(18.1833, grad_fn=<MseLossBackward0>)\n",
            "651\n",
            "tensor(16.1293, grad_fn=<MseLossBackward0>)\n",
            "652\n",
            "tensor(19.9638, grad_fn=<MseLossBackward0>)\n",
            "653\n",
            "tensor(20.1741, grad_fn=<MseLossBackward0>)\n",
            "654\n",
            "tensor(18.9568, grad_fn=<MseLossBackward0>)\n",
            "655\n",
            "tensor(16.5179, grad_fn=<MseLossBackward0>)\n",
            "656\n",
            "tensor(14.4829, grad_fn=<MseLossBackward0>)\n",
            "657\n",
            "tensor(15.4585, grad_fn=<MseLossBackward0>)\n",
            "658\n",
            "tensor(13.8765, grad_fn=<MseLossBackward0>)\n",
            "659\n",
            "tensor(16.0383, grad_fn=<MseLossBackward0>)\n",
            "660\n",
            "tensor(15.5905, grad_fn=<MseLossBackward0>)\n",
            "661\n",
            "tensor(17.7788, grad_fn=<MseLossBackward0>)\n",
            "662\n",
            "tensor(14.5434, grad_fn=<MseLossBackward0>)\n",
            "663\n",
            "tensor(13.9403, grad_fn=<MseLossBackward0>)\n",
            "664\n",
            "tensor(13.2140, grad_fn=<MseLossBackward0>)\n",
            "665\n",
            "tensor(12.7622, grad_fn=<MseLossBackward0>)\n",
            "666\n",
            "tensor(14.5585, grad_fn=<MseLossBackward0>)\n",
            "667\n",
            "tensor(13.0503, grad_fn=<MseLossBackward0>)\n",
            "668\n",
            "tensor(13.1310, grad_fn=<MseLossBackward0>)\n",
            "669\n",
            "tensor(12.8068, grad_fn=<MseLossBackward0>)\n",
            "670\n",
            "tensor(13.3208, grad_fn=<MseLossBackward0>)\n",
            "671\n",
            "tensor(15.7614, grad_fn=<MseLossBackward0>)\n",
            "672\n",
            "tensor(15.3154, grad_fn=<MseLossBackward0>)\n",
            "673\n",
            "tensor(14.4510, grad_fn=<MseLossBackward0>)\n",
            "674\n",
            "tensor(14.7192, grad_fn=<MseLossBackward0>)\n",
            "675\n",
            "tensor(15.5550, grad_fn=<MseLossBackward0>)\n",
            "676\n",
            "tensor(15.3493, grad_fn=<MseLossBackward0>)\n",
            "677\n",
            "tensor(16.2833, grad_fn=<MseLossBackward0>)\n",
            "678\n",
            "tensor(16.5269, grad_fn=<MseLossBackward0>)\n",
            "679\n",
            "tensor(18.3095, grad_fn=<MseLossBackward0>)\n",
            "680\n",
            "tensor(19.0732, grad_fn=<MseLossBackward0>)\n",
            "681\n",
            "tensor(14.7571, grad_fn=<MseLossBackward0>)\n",
            "682\n",
            "tensor(14.4089, grad_fn=<MseLossBackward0>)\n",
            "683\n",
            "tensor(13.3008, grad_fn=<MseLossBackward0>)\n",
            "684\n",
            "tensor(13.2376, grad_fn=<MseLossBackward0>)\n",
            "685\n",
            "tensor(14.4048, grad_fn=<MseLossBackward0>)\n",
            "686\n",
            "tensor(12.0699, grad_fn=<MseLossBackward0>)\n",
            "687\n",
            "tensor(13.2567, grad_fn=<MseLossBackward0>)\n",
            "688\n",
            "tensor(11.4101, grad_fn=<MseLossBackward0>)\n",
            "689\n",
            "tensor(11.4973, grad_fn=<MseLossBackward0>)\n",
            "690\n",
            "tensor(13.4959, grad_fn=<MseLossBackward0>)\n",
            "691\n",
            "tensor(15.0965, grad_fn=<MseLossBackward0>)\n",
            "692\n",
            "tensor(15.8113, grad_fn=<MseLossBackward0>)\n",
            "693\n",
            "tensor(16.0023, grad_fn=<MseLossBackward0>)\n",
            "694\n",
            "tensor(15.1021, grad_fn=<MseLossBackward0>)\n",
            "695\n",
            "tensor(17.4785, grad_fn=<MseLossBackward0>)\n",
            "696\n",
            "tensor(15.7843, grad_fn=<MseLossBackward0>)\n",
            "697\n",
            "tensor(14.3902, grad_fn=<MseLossBackward0>)\n",
            "698\n",
            "tensor(16.9315, grad_fn=<MseLossBackward0>)\n",
            "699\n",
            "tensor(18.6400, grad_fn=<MseLossBackward0>)\n",
            "700\n",
            "tensor(18.0503, grad_fn=<MseLossBackward0>)\n",
            "701\n",
            "tensor(17.0244, grad_fn=<MseLossBackward0>)\n",
            "702\n",
            "tensor(15.2057, grad_fn=<MseLossBackward0>)\n",
            "703\n",
            "tensor(12.1985, grad_fn=<MseLossBackward0>)\n",
            "704\n",
            "tensor(11.9105, grad_fn=<MseLossBackward0>)\n",
            "705\n",
            "tensor(11.1107, grad_fn=<MseLossBackward0>)\n",
            "706\n",
            "tensor(15.0303, grad_fn=<MseLossBackward0>)\n",
            "707\n",
            "tensor(15.6988, grad_fn=<MseLossBackward0>)\n",
            "708\n",
            "tensor(15.1850, grad_fn=<MseLossBackward0>)\n",
            "709\n",
            "tensor(15.1835, grad_fn=<MseLossBackward0>)\n",
            "710\n",
            "tensor(13.5412, grad_fn=<MseLossBackward0>)\n",
            "711\n",
            "tensor(14.9531, grad_fn=<MseLossBackward0>)\n",
            "712\n",
            "tensor(13.3389, grad_fn=<MseLossBackward0>)\n",
            "713\n",
            "tensor(13.4824, grad_fn=<MseLossBackward0>)\n",
            "714\n",
            "tensor(13.6090, grad_fn=<MseLossBackward0>)\n",
            "715\n",
            "tensor(12.5628, grad_fn=<MseLossBackward0>)\n",
            "716\n",
            "tensor(14.2708, grad_fn=<MseLossBackward0>)\n",
            "717\n",
            "tensor(13.5020, grad_fn=<MseLossBackward0>)\n",
            "718\n",
            "tensor(16.8832, grad_fn=<MseLossBackward0>)\n",
            "719\n",
            "tensor(16.9538, grad_fn=<MseLossBackward0>)\n",
            "720\n",
            "tensor(18.5358, grad_fn=<MseLossBackward0>)\n",
            "721\n",
            "tensor(16.7367, grad_fn=<MseLossBackward0>)\n",
            "722\n",
            "tensor(15.0026, grad_fn=<MseLossBackward0>)\n",
            "723\n",
            "tensor(14.9262, grad_fn=<MseLossBackward0>)\n",
            "724\n",
            "tensor(14.0196, grad_fn=<MseLossBackward0>)\n",
            "725\n",
            "tensor(12.6564, grad_fn=<MseLossBackward0>)\n",
            "726\n",
            "tensor(14.3327, grad_fn=<MseLossBackward0>)\n",
            "727\n",
            "tensor(13.3465, grad_fn=<MseLossBackward0>)\n",
            "728\n",
            "tensor(14.3703, grad_fn=<MseLossBackward0>)\n",
            "729\n",
            "tensor(15.9941, grad_fn=<MseLossBackward0>)\n",
            "730\n",
            "tensor(14.3742, grad_fn=<MseLossBackward0>)\n",
            "731\n",
            "tensor(14.0441, grad_fn=<MseLossBackward0>)\n",
            "732\n",
            "tensor(16.3885, grad_fn=<MseLossBackward0>)\n",
            "733\n",
            "tensor(12.1030, grad_fn=<MseLossBackward0>)\n",
            "734\n",
            "tensor(11.6959, grad_fn=<MseLossBackward0>)\n",
            "735\n",
            "tensor(12.6036, grad_fn=<MseLossBackward0>)\n",
            "736\n",
            "tensor(15.1281, grad_fn=<MseLossBackward0>)\n",
            "737\n",
            "tensor(15.0520, grad_fn=<MseLossBackward0>)\n",
            "738\n",
            "tensor(13.6439, grad_fn=<MseLossBackward0>)\n",
            "739\n",
            "tensor(13.4223, grad_fn=<MseLossBackward0>)\n",
            "740\n",
            "tensor(15.9194, grad_fn=<MseLossBackward0>)\n",
            "741\n",
            "tensor(15.7210, grad_fn=<MseLossBackward0>)\n",
            "742\n",
            "tensor(17.8223, grad_fn=<MseLossBackward0>)\n",
            "743\n",
            "tensor(16.5124, grad_fn=<MseLossBackward0>)\n",
            "744\n",
            "tensor(15.6554, grad_fn=<MseLossBackward0>)\n",
            "745\n",
            "tensor(14.7308, grad_fn=<MseLossBackward0>)\n",
            "746\n",
            "tensor(15.6848, grad_fn=<MseLossBackward0>)\n",
            "747\n",
            "tensor(13.3210, grad_fn=<MseLossBackward0>)\n",
            "748\n",
            "tensor(14.9810, grad_fn=<MseLossBackward0>)\n",
            "749\n",
            "tensor(14.3154, grad_fn=<MseLossBackward0>)\n",
            "750\n",
            "tensor(13.7116, grad_fn=<MseLossBackward0>)\n",
            "751\n",
            "tensor(12.4243, grad_fn=<MseLossBackward0>)\n",
            "752\n",
            "tensor(14.0387, grad_fn=<MseLossBackward0>)\n",
            "753\n",
            "tensor(15.2645, grad_fn=<MseLossBackward0>)\n",
            "754\n",
            "tensor(12.8555, grad_fn=<MseLossBackward0>)\n",
            "755\n",
            "tensor(14.1186, grad_fn=<MseLossBackward0>)\n",
            "756\n",
            "tensor(14.0893, grad_fn=<MseLossBackward0>)\n",
            "757\n",
            "tensor(14.9259, grad_fn=<MseLossBackward0>)\n",
            "758\n",
            "tensor(14.4742, grad_fn=<MseLossBackward0>)\n",
            "759\n",
            "tensor(12.8552, grad_fn=<MseLossBackward0>)\n",
            "760\n",
            "tensor(14.0112, grad_fn=<MseLossBackward0>)\n",
            "761\n",
            "tensor(12.4739, grad_fn=<MseLossBackward0>)\n",
            "762\n",
            "tensor(13.3244, grad_fn=<MseLossBackward0>)\n",
            "763\n",
            "tensor(17.0382, grad_fn=<MseLossBackward0>)\n",
            "764\n",
            "tensor(12.8231, grad_fn=<MseLossBackward0>)\n",
            "765\n",
            "tensor(14.3835, grad_fn=<MseLossBackward0>)\n",
            "766\n",
            "tensor(14.4810, grad_fn=<MseLossBackward0>)\n",
            "767\n",
            "tensor(14.5652, grad_fn=<MseLossBackward0>)\n",
            "768\n",
            "tensor(15.5288, grad_fn=<MseLossBackward0>)\n",
            "769\n",
            "tensor(13.9941, grad_fn=<MseLossBackward0>)\n",
            "770\n",
            "tensor(15.5837, grad_fn=<MseLossBackward0>)\n",
            "771\n",
            "tensor(13.2668, grad_fn=<MseLossBackward0>)\n",
            "772\n",
            "tensor(12.3702, grad_fn=<MseLossBackward0>)\n",
            "773\n",
            "tensor(12.7209, grad_fn=<MseLossBackward0>)\n",
            "774\n",
            "tensor(12.1588, grad_fn=<MseLossBackward0>)\n",
            "775\n",
            "tensor(14.4513, grad_fn=<MseLossBackward0>)\n",
            "776\n",
            "tensor(14.1141, grad_fn=<MseLossBackward0>)\n",
            "777\n",
            "tensor(12.2386, grad_fn=<MseLossBackward0>)\n",
            "778\n",
            "tensor(14.8023, grad_fn=<MseLossBackward0>)\n",
            "779\n",
            "tensor(15.2929, grad_fn=<MseLossBackward0>)\n",
            "780\n",
            "tensor(14.2350, grad_fn=<MseLossBackward0>)\n",
            "781\n",
            "tensor(13.2941, grad_fn=<MseLossBackward0>)\n",
            "782\n",
            "tensor(11.6061, grad_fn=<MseLossBackward0>)\n",
            "783\n",
            "tensor(13.5833, grad_fn=<MseLossBackward0>)\n",
            "784\n",
            "tensor(14.6172, grad_fn=<MseLossBackward0>)\n",
            "785\n",
            "tensor(12.8767, grad_fn=<MseLossBackward0>)\n",
            "786\n",
            "tensor(14.3487, grad_fn=<MseLossBackward0>)\n",
            "787\n",
            "tensor(14.9975, grad_fn=<MseLossBackward0>)\n",
            "788\n",
            "tensor(18.1121, grad_fn=<MseLossBackward0>)\n",
            "789\n",
            "tensor(14.6716, grad_fn=<MseLossBackward0>)\n",
            "790\n",
            "tensor(11.6672, grad_fn=<MseLossBackward0>)\n",
            "791\n",
            "tensor(12.3437, grad_fn=<MseLossBackward0>)\n",
            "792\n",
            "tensor(12.1937, grad_fn=<MseLossBackward0>)\n",
            "793\n",
            "tensor(13.7406, grad_fn=<MseLossBackward0>)\n",
            "794\n",
            "tensor(13.9420, grad_fn=<MseLossBackward0>)\n",
            "795\n",
            "tensor(13.5698, grad_fn=<MseLossBackward0>)\n",
            "796\n",
            "tensor(14.2048, grad_fn=<MseLossBackward0>)\n",
            "797\n",
            "tensor(10.2751, grad_fn=<MseLossBackward0>)\n",
            "798\n",
            "tensor(11.5683, grad_fn=<MseLossBackward0>)\n",
            "799\n",
            "tensor(14.8031, grad_fn=<MseLossBackward0>)\n",
            "800\n",
            "tensor(10.3591, grad_fn=<MseLossBackward0>)\n",
            "801\n",
            "tensor(13.4830, grad_fn=<MseLossBackward0>)\n",
            "802\n",
            "tensor(13.3974, grad_fn=<MseLossBackward0>)\n",
            "803\n",
            "tensor(11.5667, grad_fn=<MseLossBackward0>)\n",
            "804\n",
            "tensor(13.5711, grad_fn=<MseLossBackward0>)\n",
            "805\n",
            "tensor(11.6255, grad_fn=<MseLossBackward0>)\n",
            "806\n",
            "tensor(14.4735, grad_fn=<MseLossBackward0>)\n",
            "807\n",
            "tensor(16.2348, grad_fn=<MseLossBackward0>)\n",
            "808\n",
            "tensor(14.1575, grad_fn=<MseLossBackward0>)\n",
            "809\n",
            "tensor(16.3867, grad_fn=<MseLossBackward0>)\n",
            "810\n",
            "tensor(11.7921, grad_fn=<MseLossBackward0>)\n",
            "811\n",
            "tensor(12.2287, grad_fn=<MseLossBackward0>)\n",
            "812\n",
            "tensor(13.6961, grad_fn=<MseLossBackward0>)\n",
            "813\n",
            "tensor(11.6821, grad_fn=<MseLossBackward0>)\n",
            "814\n",
            "tensor(13.4703, grad_fn=<MseLossBackward0>)\n",
            "815\n",
            "tensor(12.1191, grad_fn=<MseLossBackward0>)\n",
            "816\n",
            "tensor(12.1713, grad_fn=<MseLossBackward0>)\n",
            "817\n",
            "tensor(12.3981, grad_fn=<MseLossBackward0>)\n",
            "818\n",
            "tensor(12.6549, grad_fn=<MseLossBackward0>)\n",
            "819\n",
            "tensor(13.4078, grad_fn=<MseLossBackward0>)\n",
            "820\n",
            "tensor(12.1028, grad_fn=<MseLossBackward0>)\n",
            "821\n",
            "tensor(13.0453, grad_fn=<MseLossBackward0>)\n",
            "822\n",
            "tensor(13.7967, grad_fn=<MseLossBackward0>)\n",
            "823\n",
            "tensor(12.6829, grad_fn=<MseLossBackward0>)\n",
            "824\n",
            "tensor(16.3522, grad_fn=<MseLossBackward0>)\n",
            "825\n",
            "tensor(14.9119, grad_fn=<MseLossBackward0>)\n",
            "826\n",
            "tensor(10.9305, grad_fn=<MseLossBackward0>)\n",
            "827\n",
            "tensor(15.7986, grad_fn=<MseLossBackward0>)\n",
            "828\n",
            "tensor(11.4749, grad_fn=<MseLossBackward0>)\n",
            "829\n",
            "tensor(13.5489, grad_fn=<MseLossBackward0>)\n",
            "830\n",
            "tensor(14.6980, grad_fn=<MseLossBackward0>)\n",
            "831\n",
            "tensor(13.8944, grad_fn=<MseLossBackward0>)\n",
            "832\n",
            "tensor(16.4058, grad_fn=<MseLossBackward0>)\n",
            "833\n",
            "tensor(12.8143, grad_fn=<MseLossBackward0>)\n",
            "834\n",
            "tensor(11.9139, grad_fn=<MseLossBackward0>)\n",
            "835\n",
            "tensor(12.3918, grad_fn=<MseLossBackward0>)\n",
            "836\n",
            "tensor(10.2904, grad_fn=<MseLossBackward0>)\n",
            "837\n",
            "tensor(12.3559, grad_fn=<MseLossBackward0>)\n",
            "838\n",
            "tensor(13.2180, grad_fn=<MseLossBackward0>)\n",
            "839\n",
            "tensor(10.3495, grad_fn=<MseLossBackward0>)\n",
            "840\n",
            "tensor(11.7700, grad_fn=<MseLossBackward0>)\n",
            "841\n",
            "tensor(11.8702, grad_fn=<MseLossBackward0>)\n",
            "842\n",
            "tensor(11.5180, grad_fn=<MseLossBackward0>)\n",
            "843\n",
            "tensor(12.6851, grad_fn=<MseLossBackward0>)\n",
            "844\n",
            "tensor(12.8335, grad_fn=<MseLossBackward0>)\n",
            "845\n",
            "tensor(12.4438, grad_fn=<MseLossBackward0>)\n",
            "846\n",
            "tensor(13.0161, grad_fn=<MseLossBackward0>)\n",
            "847\n",
            "tensor(13.0078, grad_fn=<MseLossBackward0>)\n",
            "848\n",
            "tensor(13.8213, grad_fn=<MseLossBackward0>)\n",
            "849\n",
            "tensor(13.8777, grad_fn=<MseLossBackward0>)\n",
            "850\n",
            "tensor(12.8157, grad_fn=<MseLossBackward0>)\n",
            "851\n",
            "tensor(14.0652, grad_fn=<MseLossBackward0>)\n",
            "852\n",
            "tensor(12.2854, grad_fn=<MseLossBackward0>)\n",
            "853\n",
            "tensor(12.4887, grad_fn=<MseLossBackward0>)\n",
            "854\n",
            "tensor(10.4619, grad_fn=<MseLossBackward0>)\n",
            "855\n",
            "tensor(9.5826, grad_fn=<MseLossBackward0>)\n",
            "856\n",
            "tensor(9.1953, grad_fn=<MseLossBackward0>)\n",
            "857\n",
            "tensor(13.0669, grad_fn=<MseLossBackward0>)\n",
            "858\n",
            "tensor(11.1222, grad_fn=<MseLossBackward0>)\n",
            "859\n",
            "tensor(13.6255, grad_fn=<MseLossBackward0>)\n",
            "860\n",
            "tensor(14.4323, grad_fn=<MseLossBackward0>)\n",
            "861\n",
            "tensor(13.2904, grad_fn=<MseLossBackward0>)\n",
            "862\n",
            "tensor(14.5963, grad_fn=<MseLossBackward0>)\n",
            "863\n",
            "tensor(12.7587, grad_fn=<MseLossBackward0>)\n",
            "864\n",
            "tensor(10.1160, grad_fn=<MseLossBackward0>)\n",
            "865\n",
            "tensor(14.3507, grad_fn=<MseLossBackward0>)\n",
            "866\n",
            "tensor(13.3667, grad_fn=<MseLossBackward0>)\n",
            "867\n",
            "tensor(12.9470, grad_fn=<MseLossBackward0>)\n",
            "868\n",
            "tensor(10.9787, grad_fn=<MseLossBackward0>)\n",
            "869\n",
            "tensor(11.5162, grad_fn=<MseLossBackward0>)\n",
            "870\n",
            "tensor(13.7863, grad_fn=<MseLossBackward0>)\n",
            "871\n",
            "tensor(10.5116, grad_fn=<MseLossBackward0>)\n",
            "872\n",
            "tensor(13.1812, grad_fn=<MseLossBackward0>)\n",
            "873\n",
            "tensor(11.5435, grad_fn=<MseLossBackward0>)\n",
            "874\n",
            "tensor(12.8820, grad_fn=<MseLossBackward0>)\n",
            "875\n",
            "tensor(13.7730, grad_fn=<MseLossBackward0>)\n",
            "876\n",
            "tensor(11.1634, grad_fn=<MseLossBackward0>)\n",
            "877\n",
            "tensor(14.4583, grad_fn=<MseLossBackward0>)\n",
            "878\n",
            "tensor(13.1119, grad_fn=<MseLossBackward0>)\n",
            "879\n",
            "tensor(15.2491, grad_fn=<MseLossBackward0>)\n",
            "880\n",
            "tensor(13.8239, grad_fn=<MseLossBackward0>)\n",
            "881\n",
            "tensor(12.1438, grad_fn=<MseLossBackward0>)\n",
            "882\n",
            "tensor(11.7410, grad_fn=<MseLossBackward0>)\n",
            "883\n",
            "tensor(12.9374, grad_fn=<MseLossBackward0>)\n",
            "884\n",
            "tensor(14.9799, grad_fn=<MseLossBackward0>)\n",
            "885\n",
            "tensor(12.1059, grad_fn=<MseLossBackward0>)\n",
            "886\n",
            "tensor(12.1173, grad_fn=<MseLossBackward0>)\n",
            "887\n",
            "tensor(12.3900, grad_fn=<MseLossBackward0>)\n",
            "888\n",
            "tensor(11.6510, grad_fn=<MseLossBackward0>)\n",
            "889\n",
            "tensor(14.8030, grad_fn=<MseLossBackward0>)\n",
            "890\n",
            "tensor(15.5610, grad_fn=<MseLossBackward0>)\n",
            "891\n",
            "tensor(17.0476, grad_fn=<MseLossBackward0>)\n",
            "892\n",
            "tensor(14.1067, grad_fn=<MseLossBackward0>)\n",
            "893\n",
            "tensor(11.6776, grad_fn=<MseLossBackward0>)\n",
            "894\n",
            "tensor(13.3634, grad_fn=<MseLossBackward0>)\n",
            "895\n",
            "tensor(10.9128, grad_fn=<MseLossBackward0>)\n",
            "896\n",
            "tensor(10.8575, grad_fn=<MseLossBackward0>)\n",
            "897\n",
            "tensor(13.2085, grad_fn=<MseLossBackward0>)\n",
            "898\n",
            "tensor(12.5548, grad_fn=<MseLossBackward0>)\n",
            "899\n",
            "tensor(12.8470, grad_fn=<MseLossBackward0>)\n",
            "900\n",
            "tensor(12.5655, grad_fn=<MseLossBackward0>)\n",
            "901\n",
            "tensor(13.5678, grad_fn=<MseLossBackward0>)\n",
            "902\n",
            "tensor(15.4873, grad_fn=<MseLossBackward0>)\n",
            "903\n",
            "tensor(13.0002, grad_fn=<MseLossBackward0>)\n",
            "904\n",
            "tensor(13.0231, grad_fn=<MseLossBackward0>)\n",
            "905\n",
            "tensor(11.5357, grad_fn=<MseLossBackward0>)\n",
            "906\n",
            "tensor(12.9153, grad_fn=<MseLossBackward0>)\n",
            "907\n",
            "tensor(11.0841, grad_fn=<MseLossBackward0>)\n",
            "908\n",
            "tensor(11.4313, grad_fn=<MseLossBackward0>)\n",
            "909\n",
            "tensor(11.4175, grad_fn=<MseLossBackward0>)\n",
            "910\n",
            "tensor(12.2555, grad_fn=<MseLossBackward0>)\n",
            "911\n",
            "tensor(12.3618, grad_fn=<MseLossBackward0>)\n",
            "912\n",
            "tensor(12.5897, grad_fn=<MseLossBackward0>)\n",
            "913\n",
            "tensor(12.5662, grad_fn=<MseLossBackward0>)\n",
            "914\n",
            "tensor(13.4644, grad_fn=<MseLossBackward0>)\n",
            "915\n",
            "tensor(17.3836, grad_fn=<MseLossBackward0>)\n",
            "916\n",
            "tensor(16.9005, grad_fn=<MseLossBackward0>)\n",
            "917\n",
            "tensor(14.3503, grad_fn=<MseLossBackward0>)\n",
            "918\n",
            "tensor(13.3755, grad_fn=<MseLossBackward0>)\n",
            "919\n",
            "tensor(12.2110, grad_fn=<MseLossBackward0>)\n",
            "920\n",
            "tensor(11.8779, grad_fn=<MseLossBackward0>)\n",
            "921\n",
            "tensor(11.9661, grad_fn=<MseLossBackward0>)\n",
            "922\n",
            "tensor(11.8997, grad_fn=<MseLossBackward0>)\n",
            "923\n",
            "tensor(15.1525, grad_fn=<MseLossBackward0>)\n",
            "924\n",
            "tensor(12.1903, grad_fn=<MseLossBackward0>)\n",
            "925\n",
            "tensor(10.6066, grad_fn=<MseLossBackward0>)\n",
            "926\n",
            "tensor(12.9487, grad_fn=<MseLossBackward0>)\n",
            "927\n",
            "tensor(12.5237, grad_fn=<MseLossBackward0>)\n",
            "928\n",
            "tensor(10.9997, grad_fn=<MseLossBackward0>)\n",
            "929\n",
            "tensor(11.0899, grad_fn=<MseLossBackward0>)\n",
            "930\n",
            "tensor(12.9190, grad_fn=<MseLossBackward0>)\n",
            "931\n",
            "tensor(10.5243, grad_fn=<MseLossBackward0>)\n",
            "932\n",
            "tensor(10.6500, grad_fn=<MseLossBackward0>)\n",
            "933\n",
            "tensor(10.3668, grad_fn=<MseLossBackward0>)\n",
            "934\n",
            "tensor(10.6578, grad_fn=<MseLossBackward0>)\n",
            "935\n",
            "tensor(11.1130, grad_fn=<MseLossBackward0>)\n",
            "936\n",
            "tensor(10.1400, grad_fn=<MseLossBackward0>)\n",
            "937\n",
            "tensor(12.1062, grad_fn=<MseLossBackward0>)\n",
            "938\n",
            "tensor(12.6607, grad_fn=<MseLossBackward0>)\n",
            "939\n",
            "tensor(14.5604, grad_fn=<MseLossBackward0>)\n",
            "940\n",
            "tensor(12.0396, grad_fn=<MseLossBackward0>)\n",
            "941\n",
            "tensor(13.9043, grad_fn=<MseLossBackward0>)\n",
            "942\n",
            "tensor(14.3495, grad_fn=<MseLossBackward0>)\n",
            "943\n",
            "tensor(12.0224, grad_fn=<MseLossBackward0>)\n",
            "944\n",
            "tensor(13.4861, grad_fn=<MseLossBackward0>)\n",
            "945\n",
            "tensor(12.2718, grad_fn=<MseLossBackward0>)\n",
            "946\n",
            "tensor(13.0763, grad_fn=<MseLossBackward0>)\n",
            "947\n",
            "tensor(12.1980, grad_fn=<MseLossBackward0>)\n",
            "948\n",
            "tensor(11.5399, grad_fn=<MseLossBackward0>)\n",
            "949\n",
            "tensor(11.3851, grad_fn=<MseLossBackward0>)\n",
            "950\n",
            "tensor(11.0898, grad_fn=<MseLossBackward0>)\n",
            "951\n",
            "tensor(11.2983, grad_fn=<MseLossBackward0>)\n",
            "952\n",
            "tensor(12.0518, grad_fn=<MseLossBackward0>)\n",
            "953\n",
            "tensor(13.5125, grad_fn=<MseLossBackward0>)\n",
            "954\n",
            "tensor(16.2926, grad_fn=<MseLossBackward0>)\n",
            "955\n",
            "tensor(14.4625, grad_fn=<MseLossBackward0>)\n",
            "956\n",
            "tensor(14.6531, grad_fn=<MseLossBackward0>)\n",
            "957\n",
            "tensor(12.2883, grad_fn=<MseLossBackward0>)\n",
            "958\n",
            "tensor(12.3268, grad_fn=<MseLossBackward0>)\n",
            "959\n",
            "tensor(10.0870, grad_fn=<MseLossBackward0>)\n",
            "960\n",
            "tensor(10.4741, grad_fn=<MseLossBackward0>)\n",
            "961\n",
            "tensor(12.3805, grad_fn=<MseLossBackward0>)\n",
            "962\n",
            "tensor(12.5141, grad_fn=<MseLossBackward0>)\n",
            "963\n",
            "tensor(13.8387, grad_fn=<MseLossBackward0>)\n",
            "964\n",
            "tensor(12.1440, grad_fn=<MseLossBackward0>)\n",
            "965\n",
            "tensor(11.5288, grad_fn=<MseLossBackward0>)\n",
            "966\n",
            "tensor(10.5600, grad_fn=<MseLossBackward0>)\n",
            "967\n",
            "tensor(10.7251, grad_fn=<MseLossBackward0>)\n",
            "968\n",
            "tensor(10.7245, grad_fn=<MseLossBackward0>)\n",
            "969\n",
            "tensor(10.5621, grad_fn=<MseLossBackward0>)\n",
            "970\n",
            "tensor(13.4453, grad_fn=<MseLossBackward0>)\n",
            "971\n",
            "tensor(11.3814, grad_fn=<MseLossBackward0>)\n",
            "972\n",
            "tensor(11.5582, grad_fn=<MseLossBackward0>)\n",
            "973\n",
            "tensor(14.4595, grad_fn=<MseLossBackward0>)\n",
            "974\n",
            "tensor(10.8656, grad_fn=<MseLossBackward0>)\n",
            "975\n",
            "tensor(11.4832, grad_fn=<MseLossBackward0>)\n",
            "976\n",
            "tensor(13.9347, grad_fn=<MseLossBackward0>)\n",
            "977\n",
            "tensor(14.0371, grad_fn=<MseLossBackward0>)\n",
            "978\n",
            "tensor(14.5365, grad_fn=<MseLossBackward0>)\n",
            "979\n",
            "tensor(15.7305, grad_fn=<MseLossBackward0>)\n",
            "980\n",
            "tensor(13.9703, grad_fn=<MseLossBackward0>)\n",
            "981\n",
            "tensor(11.7630, grad_fn=<MseLossBackward0>)\n",
            "982\n",
            "tensor(10.7068, grad_fn=<MseLossBackward0>)\n",
            "983\n",
            "tensor(11.4860, grad_fn=<MseLossBackward0>)\n",
            "984\n",
            "tensor(10.8001, grad_fn=<MseLossBackward0>)\n",
            "985\n",
            "tensor(12.9018, grad_fn=<MseLossBackward0>)\n",
            "986\n",
            "tensor(12.4127, grad_fn=<MseLossBackward0>)\n",
            "987\n",
            "tensor(13.0184, grad_fn=<MseLossBackward0>)\n",
            "988\n",
            "tensor(11.4568, grad_fn=<MseLossBackward0>)\n",
            "989\n",
            "tensor(10.1799, grad_fn=<MseLossBackward0>)\n",
            "990\n",
            "tensor(9.4632, grad_fn=<MseLossBackward0>)\n",
            "991\n",
            "tensor(11.3033, grad_fn=<MseLossBackward0>)\n",
            "992\n",
            "tensor(10.9206, grad_fn=<MseLossBackward0>)\n",
            "993\n",
            "tensor(11.6004, grad_fn=<MseLossBackward0>)\n",
            "994\n",
            "tensor(12.4561, grad_fn=<MseLossBackward0>)\n",
            "995\n",
            "tensor(12.7993, grad_fn=<MseLossBackward0>)\n",
            "996\n",
            "tensor(10.7776, grad_fn=<MseLossBackward0>)\n",
            "997\n",
            "tensor(12.1187, grad_fn=<MseLossBackward0>)\n",
            "998\n",
            "tensor(11.3230, grad_fn=<MseLossBackward0>)\n",
            "999\n",
            "tensor(11.2791, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "#Train our model and evaluate on the test set\n",
        "train_pred = []\n",
        "train_values = []\n",
        "val_pred = []\n",
        "val_values = []\n",
        "for e in range(1000):\n",
        "    print(e)\n",
        "    model.train()     # Optional when not using Model Specific layer\n",
        "    for data in train_loader:\n",
        "\n",
        "      optim.zero_grad()\n",
        "      data.x = data.x.to(device, dtype = torch.float)\n",
        "      data.y = data.y.to(device, dtype = torch.float)\n",
        "\n",
        "      pred = model(data.x, data.edge_index)\n",
        "      \n",
        "      loss = F.mse_loss(pred.squeeze(), data.y.squeeze())\n",
        "      pred_np = pred.detach().numpy()\n",
        "      data.y_np = data.y.detach().numpy() \n",
        "      train_pred.append(pred_np)\n",
        "      train_values.append(data.y_np)\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "    \n",
        "    model.eval()\n",
        "    for data in test_loader:\n",
        "           # Optional when not using Model Specific layer\n",
        "      optim.zero_grad()\n",
        "      data.x = data.x.to(device, dtype = torch.float)\n",
        "      data.y = data.y.to(device, dtype = torch.float)\n",
        "      \n",
        "      pred = model(data.x, data.edge_index)\n",
        "      \n",
        "      loss = F.mse_loss(pred.squeeze(), data.y.squeeze())\n",
        "      pred_np = pred.detach().numpy()\n",
        "      data.y_np = data.y.detach().numpy() \n",
        "      val_pred.append(pred_np)\n",
        "      val_values.append(data.y_np)\n",
        "      print(loss)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlb71wX7FCQV"
      },
      "source": [
        "##Visualise learning curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP4-OfnstoZf"
      },
      "outputs": [],
      "source": [
        "#Obtain the training/validation curves\n",
        "def train_graph(pred, train, val_pred, val_train, epochs):\n",
        "\n",
        "  median_scores_train = []\n",
        "  median_scores_test = []\n",
        "\n",
        "  mean_scores_train = []\n",
        "  mean_scores_test = []\n",
        "\n",
        "  for i in range(1,epochs):\n",
        "    median_scores_train.append(median_absolute_error(pred[i], train[i]))\n",
        "    mean_scores_train.append(mean_absolute_error(pred[i], train[i]))\n",
        "    median_scores_test.append(median_absolute_error(val_pred[i], val_train[i]))\n",
        "    mean_scores_test.append(mean_absolute_error(val_pred[i], val_train[i]))\n",
        "\n",
        "  epoch = []\n",
        "  for i in range(1,epochs):\n",
        "    epoch.append(i)\n",
        "\n",
        "  ysmoothed_median_train = gaussian_filter1d(median_scores_train, sigma=2)\n",
        "  ysmoothed_mean_train = gaussian_filter1d(mean_scores_train, sigma=2)\n",
        "\n",
        "  ysmoothed_median_test = gaussian_filter1d(median_scores_test, sigma=2)\n",
        "  ysmoothed_mean_test = gaussian_filter1d(mean_scores_test, sigma=2)\n",
        "\n",
        "  plt.rcParams['figure.figsize'] = [7, 7]\n",
        "  plt.plot(epoch, ysmoothed_median_train, label = 'Train Median Absolute error')\n",
        "  plt.plot(epoch, ysmoothed_mean_train, label = 'Train Mean Absolute error')\n",
        "\n",
        "  plt.plot(epoch, ysmoothed_median_test, label = 'Test Median Absolute error')\n",
        "  plt.plot(epoch, ysmoothed_mean_test, label = 'Test Mean Absolute error')\n",
        "\n",
        "  listOf_Xticks = np.arange(0, epochs, epochs/10)\n",
        "  plt.xticks(listOf_Xticks)\n",
        "\n",
        "  plt.ylim([0, 12])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Error\")\n",
        "  plt.title(\"Median/Mean absolute error vs Epochs(GCN)\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  print(\"Mimimum test median absolute error\", min(median_scores_test))\n",
        "  print(\"Mimimum test mean absolute error\", min(mean_scores_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tWqoOkn7uw0m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "a240c90d-4d78-4778-eba2-74d6092f6818"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mimimum test median absolute error 1.0637054\n",
            "Mimimum test mean absolute error 2.1767857\n"
          ]
        }
      ],
      "source": [
        "#Learning curves for the GCN\n",
        "train_graph(train_pred, train_values, val_pred, val_values, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHySZc5usLaR"
      },
      "source": [
        "##Test Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iHwzv1dGsNlI"
      },
      "outputs": [],
      "source": [
        "val_pred = []\n",
        "val_values = []\n",
        "for data in test_loader:\n",
        "           # Optional when not using Model Specific layer\n",
        "      data.x = data.x.to(device, dtype = torch.float)\n",
        "      data.y = data.y.to(device, dtype = torch.float)\n",
        "      \n",
        "      pred = model(data.x, data.edge_index)\n",
        "      \n",
        "      loss = F.mse_loss(pred.squeeze(), data.y.squeeze())\n",
        "      pred_np = pred.detach().numpy()\n",
        "      data.y_np = data.y.detach().numpy() \n",
        "      val_pred.append(pred_np)\n",
        "      val_values.append(data.y_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "iMnCaA_VsvuQ"
      },
      "outputs": [],
      "source": [
        "val_pred = np.array(val_pred)\n",
        "val_values = np.array(val_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "B225A5JjtlOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee17c382-3e85-484f-ddb1-c4d8014951c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5182743"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "median_absolute_error(val_pred.flatten(), val_values.flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "oUUFRj_J0hqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81449f4-e812-4202-a530-764d8d99cc0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.4276462"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "mean_absolute_error(val_pred.flatten(), val_values.flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz-qbE64Cype"
      },
      "source": [
        "#Data preparation(CNN and MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2zX_5GgyQo6Y"
      },
      "outputs": [],
      "source": [
        "#Creating our dataset\n",
        "for i in range(1,50):\n",
        "  globals()['min_df_'+str(i)] = graph_dataset(globals()['G_'+str(i)])\n",
        "  globals()['min_df_'+str(i)]\n",
        "  for index, row in globals()['min_df_'+str(i)].iterrows():\n",
        "    globals()['G_'+str(i)].add_edge(row['edge_1'], row['edge_2'])\n",
        "\n",
        "  globals()['min_df_'+str(i)].sort_values( by = ['edge_1'], inplace = True) \n",
        "  globals()['min_df_'+str(i)]['distance'] = globals()['min_df_'+str(i)]['distance'].astype(int)\n",
        "  pow={0:globals()['min_df_'+str(i)].iloc[0, 2], 1:globals()['min_df_'+str(i)].iloc[1, 2], 2:globals()['min_df_'+str(i)].iloc[2, 2], 3:globals()['min_df_'+str(i)].iloc[3, 2], 4:globals()['min_df_'+str(i)].iloc[4, 2]}\n",
        "  nx.set_node_attributes(globals()['G_'+str(i)], pow, 'y')\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UWJVrvgSQygn"
      },
      "outputs": [],
      "source": [
        "#Data preparation\n",
        "Graph = []\n",
        "coord_x = []\n",
        "coord_y = []\n",
        "coord_near_x = []\n",
        "coord_near_y = []\n",
        "distance = []\n",
        "for i in range(1, 200):\n",
        "    for index, row in globals()['min_df_'+str(i)].iterrows():\n",
        "      Graph.append(i)\n",
        "      coord_x.append(nx.get_node_attributes(globals()['G_'+str(i)], 'pos_x')[row['edge_1']])\n",
        "      \n",
        "      coord_y.append(nx.get_node_attributes(globals()['G_'+str(i)], 'pos_y')[row['edge_1']])\n",
        "\n",
        "      distance.append(row['distance'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "9y5PwNZxTbd_"
      },
      "outputs": [],
      "source": [
        "#Assigning values in the dataset\n",
        "combined_data = pd.DataFrame(columns = ['Graph', 'coord_x', 'coord_y', 'distance'])\n",
        "combined_data['Graph'] = Graph\n",
        "combined_data['coord_x'] = coord_x\n",
        "combined_data['coord_y'] = coord_y\n",
        "combined_data['distance'] = distance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "TZWrvVElY3wH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "cb173e30-f187-4de6-a7fa-94f0061ec74f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Graph  coord_x  coord_y  distance\n",
              "0        1       51       60     20.00\n",
              "1        1       45       40     13.00\n",
              "2        1       42       53     25.00\n",
              "3        1       10       60     17.00\n",
              "4        1       18       45     17.00\n",
              "..     ...      ...      ...       ...\n",
              "991    199       52       69     27.29\n",
              "992    199       48       42     27.29\n",
              "993    199       50       60     33.53\n",
              "994    199       16       68     18.11\n",
              "995    199       18       50     33.53\n",
              "\n",
              "[996 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-013db409-80fc-4aa2-ae32-a50fbb431d5b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Graph</th>\n",
              "      <th>coord_x</th>\n",
              "      <th>coord_y</th>\n",
              "      <th>distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>60</td>\n",
              "      <td>20.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>40</td>\n",
              "      <td>13.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>53</td>\n",
              "      <td>25.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>60</td>\n",
              "      <td>17.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>45</td>\n",
              "      <td>17.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>199</td>\n",
              "      <td>52</td>\n",
              "      <td>69</td>\n",
              "      <td>27.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>199</td>\n",
              "      <td>48</td>\n",
              "      <td>42</td>\n",
              "      <td>27.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>199</td>\n",
              "      <td>50</td>\n",
              "      <td>60</td>\n",
              "      <td>33.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>199</td>\n",
              "      <td>16</td>\n",
              "      <td>68</td>\n",
              "      <td>18.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>199</td>\n",
              "      <td>18</td>\n",
              "      <td>50</td>\n",
              "      <td>33.53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>996 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-013db409-80fc-4aa2-ae32-a50fbb431d5b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-013db409-80fc-4aa2-ae32-a50fbb431d5b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-013db409-80fc-4aa2-ae32-a50fbb431d5b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "#Look at the first few rows of our dataset\n",
        "combined_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1LWD75nFXup"
      },
      "source": [
        "#MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23xVy3wGDPhx"
      },
      "source": [
        "##Train/Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "jS5MjSTSXoKC"
      },
      "outputs": [],
      "source": [
        "#Splitting our training and testing data\n",
        "x = combined_data[['coord_x', 'coord_y']]\n",
        "y = combined_data[['distance']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.10, random_state=42, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtS0u_dfFkKf"
      },
      "source": [
        "##Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "3hS6z66kYvo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4acdaa6c-0168-4716-ab73-9af0e311a354"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "#Initialise our MLP regressor\n",
        "clf = MLPRegressor(random_state=20, max_iter=300).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaWPIRJpEU0e"
      },
      "source": [
        "##Evaluate for the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "KnVd8--ilpMB"
      },
      "outputs": [],
      "source": [
        "#Predict on test set\n",
        "pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "r-VJYpbhl3mV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba98d4e6-2d7d-4d0f-cd1b-e255813f05e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.071695174861901"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#Mean absolute error for the MLP\n",
        "mean_absolute_error(y_test, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KcJX-ajvlc6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca1bb354-349a-4b99-eb06-0f6299dfd35e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.514080452828173"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "#Median absolute error for the MLP\n",
        "median_absolute_error(y_test, pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTTu-CHpD7cc"
      },
      "source": [
        "#Convolution Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SvlWLolDvr9"
      },
      "source": [
        "##Prepare data for our CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "REedzAcNmD6z"
      },
      "outputs": [],
      "source": [
        "#Reshape values for CNN\n",
        "x = x.values\n",
        "x = x.reshape(x.shape[0], x.shape[1], 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw3QiJ9_F2nE"
      },
      "source": [
        "##Train/Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ISUn-1a-mGk7"
      },
      "outputs": [],
      "source": [
        "#Train/Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state=42, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_iIlX1pF6hv"
      },
      "source": [
        "##Define our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Yts27nQcmNKN"
      },
      "outputs": [],
      "source": [
        "#Define our CNN \n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, 2, activation=\"relu\", input_shape=(2, 1)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(32, activation=\"relu\"))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss=[\"mae\"], optimizer=\"adam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "LNjfNSXNNhIe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a548e573-9229-4f09-daa0-e124e99dbb4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 1, 32)             96        \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,321\n",
            "Trainable params: 4,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Model architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMzZAVV-F8tT"
      },
      "source": [
        "##Train CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "cEfW3M2qmQpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450cd6f5-ac96-4b42-9f9e-1e1ae257da0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "25/25 [==============================] - 1s 10ms/step - loss: 18.9552 - val_loss: 8.0024\n",
            "Epoch 2/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 6.5964 - val_loss: 6.3200\n",
            "Epoch 3/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 6.3203 - val_loss: 6.1248\n",
            "Epoch 4/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 6.1977 - val_loss: 6.2390\n",
            "Epoch 5/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 6.1758 - val_loss: 6.1781\n",
            "Epoch 6/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 6.1778 - val_loss: 6.0845\n",
            "Epoch 7/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 6.1326 - val_loss: 5.9063\n",
            "Epoch 8/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 6.1606 - val_loss: 5.9973\n",
            "Epoch 9/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 6.0813 - val_loss: 6.2451\n",
            "Epoch 10/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 6.0997 - val_loss: 6.1123\n",
            "Epoch 11/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 6.0594 - val_loss: 5.7955\n",
            "Epoch 12/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 6.0284 - val_loss: 5.8613\n",
            "Epoch 13/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 6.0184 - val_loss: 6.0137\n",
            "Epoch 14/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 6.0006 - val_loss: 5.7875\n",
            "Epoch 15/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.9556 - val_loss: 5.9693\n",
            "Epoch 16/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.9610 - val_loss: 5.6771\n",
            "Epoch 17/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 6.0548 - val_loss: 5.6716\n",
            "Epoch 18/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.9579 - val_loss: 5.7233\n",
            "Epoch 19/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 6.0087 - val_loss: 5.6676\n",
            "Epoch 20/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.9531 - val_loss: 5.8440\n",
            "Epoch 21/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.9097 - val_loss: 5.7191\n",
            "Epoch 22/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.9053 - val_loss: 5.5618\n",
            "Epoch 23/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.8993 - val_loss: 5.6205\n",
            "Epoch 24/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.9200 - val_loss: 5.5790\n",
            "Epoch 25/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.8402 - val_loss: 5.4012\n",
            "Epoch 26/300\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 5.8965 - val_loss: 5.4678\n",
            "Epoch 27/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 5.8618 - val_loss: 5.4802\n",
            "Epoch 28/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5.8127 - val_loss: 5.6891\n",
            "Epoch 29/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5.9207 - val_loss: 5.5781\n",
            "Epoch 30/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5.8760 - val_loss: 6.1138\n",
            "Epoch 31/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.8816 - val_loss: 5.6278\n",
            "Epoch 32/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.8502 - val_loss: 5.5254\n",
            "Epoch 33/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.8377 - val_loss: 5.2832\n",
            "Epoch 34/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.8975 - val_loss: 5.2268\n",
            "Epoch 35/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.9331 - val_loss: 5.2822\n",
            "Epoch 36/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.8862 - val_loss: 5.4587\n",
            "Epoch 37/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.7883 - val_loss: 5.6326\n",
            "Epoch 38/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7832 - val_loss: 5.4935\n",
            "Epoch 39/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.7529 - val_loss: 5.5765\n",
            "Epoch 40/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7664 - val_loss: 5.8541\n",
            "Epoch 41/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7858 - val_loss: 6.0221\n",
            "Epoch 42/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.8282 - val_loss: 6.5111\n",
            "Epoch 43/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7711 - val_loss: 5.3347\n",
            "Epoch 44/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.8449 - val_loss: 5.2464\n",
            "Epoch 45/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.8333 - val_loss: 5.4701\n",
            "Epoch 46/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7509 - val_loss: 6.0463\n",
            "Epoch 47/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7557 - val_loss: 5.5162\n",
            "Epoch 48/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.7282 - val_loss: 5.5228\n",
            "Epoch 49/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7883 - val_loss: 5.6984\n",
            "Epoch 50/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7697 - val_loss: 5.9806\n",
            "Epoch 51/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.8187 - val_loss: 5.8722\n",
            "Epoch 52/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7389 - val_loss: 5.7294\n",
            "Epoch 53/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.7639 - val_loss: 5.5081\n",
            "Epoch 54/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7268 - val_loss: 5.6420\n",
            "Epoch 55/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.7135 - val_loss: 5.4132\n",
            "Epoch 56/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7521 - val_loss: 5.8125\n",
            "Epoch 57/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7069 - val_loss: 5.5764\n",
            "Epoch 58/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7186 - val_loss: 5.6594\n",
            "Epoch 59/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.7309 - val_loss: 5.4010\n",
            "Epoch 60/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6898 - val_loss: 5.6128\n",
            "Epoch 61/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7086 - val_loss: 5.4660\n",
            "Epoch 62/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7012 - val_loss: 5.9236\n",
            "Epoch 63/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7134 - val_loss: 5.5860\n",
            "Epoch 64/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7221 - val_loss: 5.7275\n",
            "Epoch 65/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6870 - val_loss: 5.2371\n",
            "Epoch 66/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7619 - val_loss: 5.2222\n",
            "Epoch 67/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7158 - val_loss: 5.3027\n",
            "Epoch 68/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7296 - val_loss: 5.5946\n",
            "Epoch 69/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7152 - val_loss: 5.3942\n",
            "Epoch 70/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6848 - val_loss: 5.7310\n",
            "Epoch 71/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6916 - val_loss: 5.6499\n",
            "Epoch 72/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7335 - val_loss: 5.8617\n",
            "Epoch 73/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7056 - val_loss: 5.6436\n",
            "Epoch 74/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6557 - val_loss: 5.8270\n",
            "Epoch 75/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7100 - val_loss: 5.5826\n",
            "Epoch 76/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.7003 - val_loss: 5.3393\n",
            "Epoch 77/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6625 - val_loss: 5.4566\n",
            "Epoch 78/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7076 - val_loss: 5.4349\n",
            "Epoch 79/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7154 - val_loss: 5.6398\n",
            "Epoch 80/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7993 - val_loss: 5.3962\n",
            "Epoch 81/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6726 - val_loss: 5.0898\n",
            "Epoch 82/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7067 - val_loss: 5.3719\n",
            "Epoch 83/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7029 - val_loss: 5.5564\n",
            "Epoch 84/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6649 - val_loss: 5.5130\n",
            "Epoch 85/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6895 - val_loss: 5.8273\n",
            "Epoch 86/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6778 - val_loss: 5.8006\n",
            "Epoch 87/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7974 - val_loss: 5.6721\n",
            "Epoch 88/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6894 - val_loss: 5.7378\n",
            "Epoch 89/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7573 - val_loss: 5.8329\n",
            "Epoch 90/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6893 - val_loss: 5.4613\n",
            "Epoch 91/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6687 - val_loss: 5.6360\n",
            "Epoch 92/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6417 - val_loss: 5.7950\n",
            "Epoch 93/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6602 - val_loss: 5.4175\n",
            "Epoch 94/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6179 - val_loss: 5.4348\n",
            "Epoch 95/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6220 - val_loss: 5.8252\n",
            "Epoch 96/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7165 - val_loss: 5.6590\n",
            "Epoch 97/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6194 - val_loss: 5.4613\n",
            "Epoch 98/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6085 - val_loss: 5.2750\n",
            "Epoch 99/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6853 - val_loss: 5.3836\n",
            "Epoch 100/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6026 - val_loss: 5.3424\n",
            "Epoch 101/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6191 - val_loss: 5.8177\n",
            "Epoch 102/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.7318 - val_loss: 5.3876\n",
            "Epoch 103/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6480 - val_loss: 6.0859\n",
            "Epoch 104/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.7187 - val_loss: 5.9599\n",
            "Epoch 105/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6970 - val_loss: 5.5097\n",
            "Epoch 106/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6669 - val_loss: 5.8051\n",
            "Epoch 107/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6075 - val_loss: 5.1170\n",
            "Epoch 108/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6172 - val_loss: 5.2881\n",
            "Epoch 109/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5914 - val_loss: 5.5009\n",
            "Epoch 110/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6512 - val_loss: 5.1611\n",
            "Epoch 111/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6207 - val_loss: 5.2871\n",
            "Epoch 112/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6172 - val_loss: 5.0299\n",
            "Epoch 113/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.7499 - val_loss: 5.2626\n",
            "Epoch 114/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6426 - val_loss: 5.2974\n",
            "Epoch 115/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6329 - val_loss: 5.0809\n",
            "Epoch 116/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6477 - val_loss: 5.3729\n",
            "Epoch 117/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6097 - val_loss: 5.3741\n",
            "Epoch 118/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5912 - val_loss: 5.4872\n",
            "Epoch 119/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5858 - val_loss: 5.3959\n",
            "Epoch 120/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6098 - val_loss: 5.0389\n",
            "Epoch 121/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6363 - val_loss: 5.2220\n",
            "Epoch 122/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6056 - val_loss: 5.1943\n",
            "Epoch 123/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6157 - val_loss: 5.4654\n",
            "Epoch 124/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5695 - val_loss: 5.0861\n",
            "Epoch 125/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6108 - val_loss: 5.2694\n",
            "Epoch 126/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6375 - val_loss: 5.1378\n",
            "Epoch 127/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5691 - val_loss: 5.8253\n",
            "Epoch 128/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5970 - val_loss: 5.2708\n",
            "Epoch 129/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6069 - val_loss: 5.3718\n",
            "Epoch 130/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5732 - val_loss: 5.4421\n",
            "Epoch 131/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5713 - val_loss: 5.7213\n",
            "Epoch 132/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6282 - val_loss: 5.6817\n",
            "Epoch 133/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5866 - val_loss: 5.8224\n",
            "Epoch 134/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5563 - val_loss: 5.1845\n",
            "Epoch 135/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6150 - val_loss: 5.8849\n",
            "Epoch 136/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6010 - val_loss: 5.7591\n",
            "Epoch 137/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5666 - val_loss: 5.6202\n",
            "Epoch 138/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5778 - val_loss: 5.5010\n",
            "Epoch 139/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5859 - val_loss: 5.2923\n",
            "Epoch 140/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.6149 - val_loss: 5.6822\n",
            "Epoch 141/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5537 - val_loss: 5.4710\n",
            "Epoch 142/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5562 - val_loss: 5.3677\n",
            "Epoch 143/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5700 - val_loss: 5.6084\n",
            "Epoch 144/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5304 - val_loss: 5.3561\n",
            "Epoch 145/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5376 - val_loss: 5.4624\n",
            "Epoch 146/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5542 - val_loss: 5.5069\n",
            "Epoch 147/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5936 - val_loss: 6.0103\n",
            "Epoch 148/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5634 - val_loss: 5.5920\n",
            "Epoch 149/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5802 - val_loss: 5.3759\n",
            "Epoch 150/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6277 - val_loss: 5.4102\n",
            "Epoch 151/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6044 - val_loss: 5.0674\n",
            "Epoch 152/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5443 - val_loss: 5.3971\n",
            "Epoch 153/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5561 - val_loss: 5.3779\n",
            "Epoch 154/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5310 - val_loss: 5.1745\n",
            "Epoch 155/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5655 - val_loss: 5.1867\n",
            "Epoch 156/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.7266 - val_loss: 5.1535\n",
            "Epoch 157/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6184 - val_loss: 5.2968\n",
            "Epoch 158/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5126 - val_loss: 5.6029\n",
            "Epoch 159/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5411 - val_loss: 5.1896\n",
            "Epoch 160/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5801 - val_loss: 5.3741\n",
            "Epoch 161/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5211 - val_loss: 5.4567\n",
            "Epoch 162/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5010 - val_loss: 5.1247\n",
            "Epoch 163/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5088 - val_loss: 5.2891\n",
            "Epoch 164/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5300 - val_loss: 5.6122\n",
            "Epoch 165/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5991 - val_loss: 5.8687\n",
            "Epoch 166/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5186 - val_loss: 5.2952\n",
            "Epoch 167/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4910 - val_loss: 5.4760\n",
            "Epoch 168/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5163 - val_loss: 5.1862\n",
            "Epoch 169/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5247 - val_loss: 5.2777\n",
            "Epoch 170/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5410 - val_loss: 5.3267\n",
            "Epoch 171/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5168 - val_loss: 5.0263\n",
            "Epoch 172/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4836 - val_loss: 5.2200\n",
            "Epoch 173/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5403 - val_loss: 5.7798\n",
            "Epoch 174/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5666 - val_loss: 5.3471\n",
            "Epoch 175/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4851 - val_loss: 5.3068\n",
            "Epoch 176/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4836 - val_loss: 5.7832\n",
            "Epoch 177/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5180 - val_loss: 5.6116\n",
            "Epoch 178/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4920 - val_loss: 5.3129\n",
            "Epoch 179/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4532 - val_loss: 5.0912\n",
            "Epoch 180/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4771 - val_loss: 4.9805\n",
            "Epoch 181/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.6291 - val_loss: 5.1858\n",
            "Epoch 182/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5102 - val_loss: 5.9452\n",
            "Epoch 183/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5572 - val_loss: 5.3061\n",
            "Epoch 184/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5493 - val_loss: 5.7902\n",
            "Epoch 185/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 5.4869 - val_loss: 5.5111\n",
            "Epoch 186/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4939 - val_loss: 5.4973\n",
            "Epoch 187/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4872 - val_loss: 5.1408\n",
            "Epoch 188/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5144 - val_loss: 5.0782\n",
            "Epoch 189/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5261 - val_loss: 5.1727\n",
            "Epoch 190/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4997 - val_loss: 5.0659\n",
            "Epoch 191/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4720 - val_loss: 5.1757\n",
            "Epoch 192/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4446 - val_loss: 5.4632\n",
            "Epoch 193/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4839 - val_loss: 5.3795\n",
            "Epoch 194/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4513 - val_loss: 5.0600\n",
            "Epoch 195/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5176 - val_loss: 5.0574\n",
            "Epoch 196/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4795 - val_loss: 5.4737\n",
            "Epoch 197/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4806 - val_loss: 5.5904\n",
            "Epoch 198/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5635 - val_loss: 5.3903\n",
            "Epoch 199/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4257 - val_loss: 5.1646\n",
            "Epoch 200/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4229 - val_loss: 4.9794\n",
            "Epoch 201/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4796 - val_loss: 5.0535\n",
            "Epoch 202/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4580 - val_loss: 4.9511\n",
            "Epoch 203/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4587 - val_loss: 4.9928\n",
            "Epoch 204/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4150 - val_loss: 5.7797\n",
            "Epoch 205/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4750 - val_loss: 5.2921\n",
            "Epoch 206/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4778 - val_loss: 5.1852\n",
            "Epoch 207/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4137 - val_loss: 5.3695\n",
            "Epoch 208/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4278 - val_loss: 5.2270\n",
            "Epoch 209/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4089 - val_loss: 5.3765\n",
            "Epoch 210/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4006 - val_loss: 5.5371\n",
            "Epoch 211/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4472 - val_loss: 5.0826\n",
            "Epoch 212/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4631 - val_loss: 5.1876\n",
            "Epoch 213/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4672 - val_loss: 5.1177\n",
            "Epoch 214/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4129 - val_loss: 5.3206\n",
            "Epoch 215/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4010 - val_loss: 5.1426\n",
            "Epoch 216/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3915 - val_loss: 5.3049\n",
            "Epoch 217/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3833 - val_loss: 5.3066\n",
            "Epoch 218/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4158 - val_loss: 5.1891\n",
            "Epoch 219/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4153 - val_loss: 5.1751\n",
            "Epoch 220/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3794 - val_loss: 5.8750\n",
            "Epoch 221/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4637 - val_loss: 5.1254\n",
            "Epoch 222/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4231 - val_loss: 5.3886\n",
            "Epoch 223/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4053 - val_loss: 5.5299\n",
            "Epoch 224/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5096 - val_loss: 5.3412\n",
            "Epoch 225/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4343 - val_loss: 5.2039\n",
            "Epoch 226/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4033 - val_loss: 5.3407\n",
            "Epoch 227/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4234 - val_loss: 5.2962\n",
            "Epoch 228/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4152 - val_loss: 5.6879\n",
            "Epoch 229/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4741 - val_loss: 5.5270\n",
            "Epoch 230/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4108 - val_loss: 4.8701\n",
            "Epoch 231/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4565 - val_loss: 5.0726\n",
            "Epoch 232/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.3560 - val_loss: 4.9565\n",
            "Epoch 233/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3861 - val_loss: 5.1566\n",
            "Epoch 234/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3785 - val_loss: 5.1576\n",
            "Epoch 235/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4216 - val_loss: 5.2042\n",
            "Epoch 236/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4029 - val_loss: 5.3786\n",
            "Epoch 237/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3878 - val_loss: 5.0732\n",
            "Epoch 238/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.3371 - val_loss: 5.2706\n",
            "Epoch 239/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.3484 - val_loss: 5.1926\n",
            "Epoch 240/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3835 - val_loss: 4.7744\n",
            "Epoch 241/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3828 - val_loss: 4.9800\n",
            "Epoch 242/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3763 - val_loss: 4.9219\n",
            "Epoch 243/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3697 - val_loss: 4.9720\n",
            "Epoch 244/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4330 - val_loss: 5.2918\n",
            "Epoch 245/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.3248 - val_loss: 5.6915\n",
            "Epoch 246/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3705 - val_loss: 5.1928\n",
            "Epoch 247/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3126 - val_loss: 4.9492\n",
            "Epoch 248/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3551 - val_loss: 5.1814\n",
            "Epoch 249/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.4270 - val_loss: 4.9716\n",
            "Epoch 250/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.3750 - val_loss: 4.9262\n",
            "Epoch 251/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.3204 - val_loss: 5.2756\n",
            "Epoch 252/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.3551 - val_loss: 5.0503\n",
            "Epoch 253/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3208 - val_loss: 5.2653\n",
            "Epoch 254/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3326 - val_loss: 4.9252\n",
            "Epoch 255/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3727 - val_loss: 5.0579\n",
            "Epoch 256/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3970 - val_loss: 5.4966\n",
            "Epoch 257/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 5.3171 - val_loss: 4.9859\n",
            "Epoch 258/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3392 - val_loss: 5.0142\n",
            "Epoch 259/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3503 - val_loss: 5.4981\n",
            "Epoch 260/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3430 - val_loss: 5.5010\n",
            "Epoch 261/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3094 - val_loss: 5.1683\n",
            "Epoch 262/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3091 - val_loss: 5.1732\n",
            "Epoch 263/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3387 - val_loss: 5.6929\n",
            "Epoch 264/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3742 - val_loss: 5.9255\n",
            "Epoch 265/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3717 - val_loss: 4.9593\n",
            "Epoch 266/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3897 - val_loss: 4.8770\n",
            "Epoch 267/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3768 - val_loss: 5.1556\n",
            "Epoch 268/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3093 - val_loss: 4.9436\n",
            "Epoch 269/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4401 - val_loss: 5.3753\n",
            "Epoch 270/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3064 - val_loss: 5.1410\n",
            "Epoch 271/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2672 - val_loss: 4.9007\n",
            "Epoch 272/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2867 - val_loss: 5.8334\n",
            "Epoch 273/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2912 - val_loss: 4.9578\n",
            "Epoch 274/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2664 - val_loss: 4.9367\n",
            "Epoch 275/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.2572 - val_loss: 5.2350\n",
            "Epoch 276/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2513 - val_loss: 5.3210\n",
            "Epoch 277/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.3266 - val_loss: 5.3251\n",
            "Epoch 278/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2967 - val_loss: 4.9534\n",
            "Epoch 279/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2556 - val_loss: 5.0917\n",
            "Epoch 280/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5.2971 - val_loss: 4.8543\n",
            "Epoch 281/300\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 5.3083 - val_loss: 5.1237\n",
            "Epoch 282/300\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 5.2526 - val_loss: 5.0391\n",
            "Epoch 283/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 5.2922 - val_loss: 4.8705\n",
            "Epoch 284/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 5.2685 - val_loss: 4.9406\n",
            "Epoch 285/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2337 - val_loss: 4.8656\n",
            "Epoch 286/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2279 - val_loss: 5.0250\n",
            "Epoch 287/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.4024 - val_loss: 4.8024\n",
            "Epoch 288/300\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 5.4859 - val_loss: 4.9224\n",
            "Epoch 289/300\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 5.2882 - val_loss: 4.7340\n",
            "Epoch 290/300\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 5.2618 - val_loss: 5.0909\n",
            "Epoch 291/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5.2769 - val_loss: 5.0721\n",
            "Epoch 292/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.2764 - val_loss: 5.5616\n",
            "Epoch 293/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2628 - val_loss: 5.0316\n",
            "Epoch 294/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.1922 - val_loss: 4.9255\n",
            "Epoch 295/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2174 - val_loss: 4.9467\n",
            "Epoch 296/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2276 - val_loss: 4.9576\n",
            "Epoch 297/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.1884 - val_loss: 4.6155\n",
            "Epoch 298/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2794 - val_loss: 5.0242\n",
            "Epoch 299/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2073 - val_loss: 4.8949\n",
            "Epoch 300/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.2211 - val_loss: 4.7249\n"
          ]
        }
      ],
      "source": [
        "#Train model\n",
        "history = model.fit(X_train, y_train, batch_size=32,epochs=300, verbose=1, validation_data = (X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6B0pEN0EYwg"
      },
      "source": [
        "##Evaluate for the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "kejZ8WeMmUEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a52f97-c7f7-46f2-c9fd-627d46ca7db1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "#Predict for Test set\n",
        "ypred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "pga569npmqyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c3ef34-2626-454d-8f5f-10f0e6274348"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.5217706298828118"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "#Median absolute error for the CNN\n",
        "median_absolute_error(y_test, ypred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ypF7qIsFmtK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9fcf9b7-dc77-4821-bd43-74802c272b3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.724883182144165"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "#Nean absolute error for the CNN\n",
        "mean_absolute_error(y_test, ypred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4cPOtLG1Dzc"
      },
      "source": [
        "#Federated learning with GCN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-3qYyOarw49"
      },
      "source": [
        "Reference[2] : https://towardsdatascience.com/preserving-data-privacy-in-deep-learning-part-1-a04894f78029"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on-saKIrE1az"
      },
      "source": [
        "##Prepare dataset for each client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "1e-Nl80JZe8Y"
      },
      "outputs": [],
      "source": [
        "#Create multiple train_loader for different clients\n",
        "for i in range(0, 6):\n",
        "\n",
        "  ran = random.randint(0,175)\n",
        "  globals()['train_data_'+str(i)] = data_list[ran:ran+25]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "g0st3NYrZbKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84bc60ff-6f5a-428c-8237-3904d95c3829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,6):\n",
        "\n",
        "  globals()['train_loader_'+str(i)] = DataLoader((globals()['train_data_'+str(i)]), batch_size=10, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBe7o0PqGG6E"
      },
      "source": [
        "##Initialise FL parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "1_WdRwvU1OWL"
      },
      "outputs": [],
      "source": [
        "#FL parameters\n",
        "num_clients = 10\n",
        "num_selected = 6\n",
        "num_rounds = 150\n",
        "epochs = 50\n",
        "batch_size = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqQPRZ7PGe06"
      },
      "source": [
        "##Initialise Global model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "EqbBo35v1V2D"
      },
      "outputs": [],
      "source": [
        "#GCN Architecture\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        \n",
        "        self.linear2 = torch.nn.Linear(2, 512)\n",
        "        self.conv2 = GCNConv(512,256)\n",
        "        self.conv3 = GCNConv(256,128)\n",
        "\n",
        "        self.conv4 = GCNConv(128,64)\n",
        "\n",
        "        \n",
        "        \n",
        "        self.linear1 = torch.nn.Linear(64,1)\n",
        "        #self.linear3 = torch.nn.Linear(32,1)\n",
        "    def forward(self, x, edge_index):\n",
        "       \n",
        "        x = self.linear2(x)\n",
        "        x = x.relu()\n",
        "        \n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        \n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "\n",
        "               \n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        \n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = x.relu()\n",
        "        \n",
        "\n",
        "        x = self.linear1(x)\n",
        "        x = x.relu()\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        \n",
        "               \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7KRk4brGlNx"
      },
      "source": [
        "##Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "4PaCuj1o13vO"
      },
      "outputs": [],
      "source": [
        "#Train client model on client data\n",
        "def client_update(client_model, optimizer, train_loader, epoch):\n",
        "    \"\"\"\n",
        "    This function updates/trains client model on client data\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    for e in range(epoch):\n",
        "        for data in train_loader:\n",
        "          total_loss = 0\n",
        "          opt.zero_grad()\n",
        "          data.x = data.x.to(device, dtype = torch.float)\n",
        "          data.y = data.y.to(device, dtype = torch.float)\n",
        "          pred = model(data.x, data.edge_index)\n",
        "          loss = F.mse_loss(pred.squeeze(), data.y.squeeze())\n",
        "          #total_loss += loss.item() * data.num_graphs\n",
        "    \n",
        "          loss.backward()\n",
        "          opt.step()\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "91I9AvVO4LvZ"
      },
      "outputs": [],
      "source": [
        "#Fedaveraging\n",
        "def server_aggregate(global_model, client_models):\n",
        "    \"\"\"\n",
        "    This function has aggregation method 'mean'\n",
        "    \"\"\"\n",
        "    ### This will take simple mean of the weights of models ###\n",
        "    global_dict = global_model.state_dict()\n",
        "    for k in global_dict.keys():\n",
        "      global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() for i in range(len(client_models))], 0).mean(0)\n",
        "      global_model.load_state_dict(global_dict)\n",
        "    for model in client_models:\n",
        "      model.load_state_dict(global_model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "wpKgCQpP1-0d"
      },
      "outputs": [],
      "source": [
        "#Define global model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "global_model = GCN(256).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ussNjEzn5Af6"
      },
      "outputs": [],
      "source": [
        "#Define client model as an object of the global model\n",
        "client_models = [ global_model for _ in range(num_selected)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "2f-n9oAv5Rka"
      },
      "outputs": [],
      "source": [
        "#Initialise weight parameters\n",
        "for model in client_models:\n",
        "    model.load_state_dict(global_model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "hO3nX_QZ5o7y"
      },
      "outputs": [],
      "source": [
        "#Define optimiser\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSHUSaDM698F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a3fac6-7b57-4195-ae57-0e0047d9202b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:03<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:06<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:07<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:08<00:00,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:08<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:08<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:08<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:08<00:00,  1.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:09<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:09<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:09<00:00,  1.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:09<00:00,  1.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:11<00:00,  1.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:11<00:00,  1.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:10<00:00,  1.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 3/6 [00:05<00:05,  1.81s/it]"
          ]
        }
      ],
      "source": [
        "#Federated training with 6 clients and 150 rounds for each epoch\n",
        "for r in range(num_rounds):\n",
        "    print(\"Round\", r)\n",
        "    # select random clients\n",
        "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
        "    loss = 0\n",
        "    for i in tqdm(range(num_selected)):\n",
        "        loss += client_update(client_models[i], torch.optim.Adam(model.parameters(), lr=0.001), globals()['train_data_'+str(i)], epoch=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvC5squ26_Os"
      },
      "outputs": [],
      "source": [
        "#Aggregate client state for global model\n",
        "server_aggregate(global_model, client_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_qBqmA3HHd4"
      },
      "source": [
        "##Evaluate for GCN with federated averaging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R99tAi1TKTGJ"
      },
      "outputs": [],
      "source": [
        "#Predict for test set using the global model\n",
        "pred_ = []\n",
        "test_values = []\n",
        "for data in test_loader:\n",
        "      data.x = data.x.to(device, dtype = torch.float)\n",
        "      #data.y = data.y.to(device, dtype = torch.float)\n",
        "      pred = global_model(data.x, data.edge_index)\n",
        "\n",
        "      loss = F.mse_loss(pred.squeeze(), data.y.squeeze())\n",
        "      pred = pred.detach().numpy()\n",
        "      data.y = data.y.detach().numpy() \n",
        "      \n",
        "      pred_.append(pred)\n",
        "      test_values.append(data.y)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4EmCRGzssH-"
      },
      "outputs": [],
      "source": [
        "#Conversion\n",
        "pred_ = np.asarray(pred_)\n",
        "test_values = np.asarray(test_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAoeJ1iZKq3W"
      },
      "outputs": [],
      "source": [
        "#Median absolute error \n",
        "mae = median_absolute_error(np.ndarray.flatten(pred_), np.ndarray.flatten(test_values))\n",
        "print(mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tHzduEyKubN"
      },
      "outputs": [],
      "source": [
        "#Mean absolute error \n",
        "pred_ = np.asarray(pred_)\n",
        "test_values = np.asarray(test_values)\n",
        "\n",
        "mean_absolute_error(np.ndarray.flatten(pred_), np.ndarray.flatten(test_values))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLhHgE3A99qz"
      },
      "source": [
        "#Pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRwnoz1vJMJK"
      },
      "source": [
        "#Initialise model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVqptEtSRqTk"
      },
      "outputs": [],
      "source": [
        "#GCN Architecture\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        \n",
        "        self.linear2 = torch.nn.Linear(2, 512)\n",
        "        self.conv2 = GCNConv(512,256)\n",
        "        self.conv3 = GCNConv(256,128)\n",
        "\n",
        "        self.conv4 = GCNConv(128,64)\n",
        "\n",
        "        \n",
        "        \n",
        "        self.linear1 = torch.nn.Linear(64,1)\n",
        "        #self.linear3 = torch.nn.Linear(32,1)\n",
        "    def forward(self, x, edge_index):\n",
        "       \n",
        "        x = self.linear2(x)\n",
        "        x = x.relu()\n",
        "        \n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        \n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "\n",
        "               \n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        \n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = x.relu()\n",
        "        \n",
        "\n",
        "        x = self.linear1(x)\n",
        "        x = x.relu()\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        \n",
        "               \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8QGwcOd-I0Y"
      },
      "outputs": [],
      "source": [
        "#Define model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN(256).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsndEfVP-Len"
      },
      "outputs": [],
      "source": [
        "#Define optimiser\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF-8IBlDJecc"
      },
      "source": [
        "#Train initial network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZTxaAxp-OPl"
      },
      "outputs": [],
      "source": [
        "#Train model\n",
        "for epoch in range(1, 300):\n",
        "  print(epoch)\n",
        "  for data in train_loader:\n",
        "    total_loss = 0\n",
        "    optim.zero_grad()\n",
        "    data.x = data.x.to(device, dtype = torch.float)\n",
        "    data.y = data.y.to(device, dtype = torch.float)\n",
        "    pred = model(data.x, data.edge_index)\n",
        "    loss = F.mse_loss(pred.squeeze(), data.y.squeeze())\n",
        "    #total_loss += loss.item() * data.num_graphs\n",
        "    \n",
        "    loss.backward()\n",
        "    optim.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aZAD-GIJjOS"
      },
      "source": [
        "#Evaluate on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oZdvzlr-RVM"
      },
      "outputs": [],
      "source": [
        "#Predict for test set\n",
        "pred_ = []\n",
        "test_values = []\n",
        "for data in test_loader:\n",
        "    data.x = data.x.to(device, dtype = torch.float)\n",
        "    #data.y = data.y.to(device, dtype = torch.float)\n",
        "    pred = model(data.x, data.edge_index)\n",
        "\n",
        "    loss = F.mse_loss(pred.squeeze(), data.y.squeeze())\n",
        "    pred = pred.detach().numpy()\n",
        "    data.y = data.y.detach().numpy() \n",
        "    pred_.append(pred)\n",
        "    test_values.append(data.y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGXM39_X-UuZ"
      },
      "outputs": [],
      "source": [
        "#Median absolute error \n",
        "pred_ = np.asarray(pred_)\n",
        "test_values = np.asarray(test_values)\n",
        "\n",
        "median_absolute_error(np.ndarray.flatten(pred_), np.ndarray.flatten(test_values))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-TNDAXmBkWx"
      },
      "outputs": [],
      "source": [
        "#Mean absolute error\n",
        "pred_ = np.asarray(pred_)\n",
        "test_values = np.asarray(test_values)\n",
        "\n",
        "mean_absolute_error(np.ndarray.flatten(pred_), np.ndarray.flatten(test_values))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDoZ2t1eBSnb"
      },
      "outputs": [],
      "source": [
        "#Save model weights\n",
        "torch.save(model.state_dict(), 'model_weights_.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZpNdVjYJ65v"
      },
      "source": [
        "##Magnitude-based pruning based on lowest L1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UNBEUS2BgSU"
      },
      "outputs": [],
      "source": [
        "#Reference[3]: https://pytorch.org/tutorials/intermediate/pruning_tutorial.html\n",
        "#Pruning \n",
        "def prune_(proportion, GCN, layer1, layer2, layer3, layer4, layer5):\n",
        "  parameters_to_prune = (\n",
        "      (GCN.layer1, 'weight'),\n",
        "      (GCN.layer2, 'weight'),\n",
        "      (GCN.layer3, 'weight'),\n",
        "      (GCN.layer4, 'weight'),\n",
        "      (GCN.layer5, 'weight')\n",
        "  )\n",
        "\n",
        "  prune.global_unstructured(\n",
        "      parameters_to_prune,\n",
        "      pruning_method=prune.L1Unstructured,\n",
        "      amount=proportion,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jRl0pn6Pl3E"
      },
      "outputs": [],
      "source": [
        "#Load model weights\n",
        "model.load_state_dict(torch.load('model_weights_.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBf1uDt4PdIO"
      },
      "outputs": [],
      "source": [
        "#Apply pruning\n",
        "prune_(0.1, model, linear2, conv2.lin, conv3.lin, conv4.lin, linear1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC22HRHQQdfv"
      },
      "source": [
        "###Re-train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgVG-eXyQfJf"
      },
      "outputs": [],
      "source": [
        "#Re-Train model\n",
        "for epoch in range(1, 300):\n",
        "  print(epoch)\n",
        "  for data in train_loader:\n",
        "    total_loss = 0\n",
        "    optim.zero_grad()\n",
        "    data.x = data.x.to(device, dtype = torch.float)\n",
        "    data.y = data.y.to(device, dtype = torch.float)\n",
        "    pred = model(data.x, data.edge_index)\n",
        "    loss = F.mse_loss(pred.squeeze(), data.y.squeeze())\n",
        "    #total_loss += loss.item() * data.num_graphs\n",
        "    \n",
        "    loss.backward()\n",
        "    optim.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwyvBGe1QiB_"
      },
      "source": [
        "###Evaluate on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdqVQvDtQmqx"
      },
      "outputs": [],
      "source": [
        "#Predict for test set\n",
        "pred_ = []\n",
        "test_values = []\n",
        "for data in test_loader:\n",
        "    data.x = data.x.to(device, dtype = torch.float)\n",
        "    #data.y = data.y.to(device, dtype = torch.float)\n",
        "    pred = model(data.x, data.edge_index)\n",
        "\n",
        "    loss = F.mse_loss(pred.squeeze(), data.y.squeeze())\n",
        "    pred = pred.detach().numpy()\n",
        "    data.y = data.y.detach().numpy() \n",
        "    pred_.append(pred)\n",
        "    test_values.append(data.y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQa8THY6QrgB"
      },
      "outputs": [],
      "source": [
        "#Median absolute error \n",
        "pred_ = np.asarray(pred_)\n",
        "test_values = np.asarray(test_values)\n",
        "\n",
        "median_absolute_error(np.ndarray.flatten(pred_), np.ndarray.flatten(test_values))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOy36fp6Qt3W"
      },
      "outputs": [],
      "source": [
        "#Mean absolute error\n",
        "pred_ = np.asarray(pred_)\n",
        "test_values = np.asarray(test_values)\n",
        "\n",
        "mean_absolute_error(np.ndarray.flatten(pred_), np.ndarray.flatten(test_values))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzMfV1VreIcu"
      },
      "outputs": [],
      "source": [
        "#Initialise model\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(2, 256)\n",
        "        self.conv2 = GCNConv(256, 128)\n",
        "        #self.conv3 = GCNConv(128, 1)\n",
        "        #self.conv3 = GCNConv(data.num_features, 32)\n",
        "        self.linear1 = torch.nn.Linear(128,1)\n",
        "        # self.linear2 = torch.nn.Linear(56,1)\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        # x = self.conv3(x, edge_index)\n",
        "        # x = x.relu()\n",
        "        # x = self.conv2(x, edge_index)\n",
        "        # x = x.relu()\n",
        "        # x = self.conv2(x, edge_index)\n",
        "        # x = x.relu()\n",
        "        x = self.linear1(x)\n",
        "        # x = x.relu()\n",
        "        # x = self.linear2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmuVZWINMtix"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN(256).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUlp3GJ6Mt78"
      },
      "outputs": [],
      "source": [
        "#Threshold pruning\n",
        "class ThresholdPruning(prune.BasePruningMethod):\n",
        "    PRUNING_TYPE = \"unstructured\"\n",
        "\n",
        "    def __init__(self, threshold):\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def compute_mask(self, tensor, default_mask):\n",
        "        return torch.abs(tensor) > self.threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aInHjDxPD0X"
      },
      "outputs": [],
      "source": [
        "#Load previous weights\n",
        "model.load_state_dict(torch.load('model_weights_.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W47USN_wQ0Uv"
      },
      "source": [
        "##Magnitude-based pruning based on threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8GJLtNQPEa7"
      },
      "outputs": [],
      "source": [
        "#Reference[5]: https://stackoverflow.com/questions/61629395/how-to-prune-weights-less-than-a-threshold-in-pytorch\n",
        "#Mention parameters\n",
        "parameters_to_prune = (\n",
        "    (model.linear2, 'weight'),\n",
        "    (model.conv2.lin, 'weight'),\n",
        "    (model.conv3.lin, 'weight'),\n",
        "    (model.conv4.lin, 'weight'),    \n",
        "    (model.linear1, 'weight')\n",
        ")\n",
        "\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune, pruning_method=ThresholdPruning, threshold=0.01\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6JrOfWeReUE"
      },
      "source": [
        "###Re-train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWQ1uztMRkKv"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, 300):\n",
        "  print(epoch)\n",
        "  for data in train_loader:\n",
        "    total_loss = 0\n",
        "    optim.zero_grad()\n",
        "    data.x = data.x.to(device, dtype = torch.float)\n",
        "    data.y = data.y.to(device, dtype = torch.float)\n",
        "    pred = model(data.x, data.edge_index)\n",
        "    loss = F.mse_loss(pred.squeeze(), data.y.squeeze())\n",
        "    #total_loss += loss.item() * data.num_graphs\n",
        "    \n",
        "    loss.backward()\n",
        "    optim.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg3tDSSARnZM"
      },
      "source": [
        "###Evaluate on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgtaQCv4TqCo"
      },
      "outputs": [],
      "source": [
        "#Predict for test set\n",
        "pred_ = []\n",
        "test_values = []\n",
        "for data in test_loader:\n",
        "    data.x = data.x.to(device, dtype = torch.float)\n",
        "    #data.y = data.y.to(device, dtype = torch.float)\n",
        "    pred = model(data.x, data.edge_index)\n",
        "\n",
        "    loss = F.mse_loss(pred.squeeze(), data.y.squeeze())\n",
        "    pred = pred.detach().numpy()\n",
        "    data.y = data.y.detach().numpy() \n",
        "    pred_.append(pred)\n",
        "    test_values.append(data.y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBQh1Qw4R0aX"
      },
      "outputs": [],
      "source": [
        "#Median absolute error \n",
        "pred_ = np.asarray(pred_)\n",
        "test_values = np.asarray(test_values)\n",
        "\n",
        "median_absolute_error(np.ndarray.flatten(pred_), np.ndarray.flatten(test_values))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkx8LVBgR2ck"
      },
      "outputs": [],
      "source": [
        "#Mean absolute error\n",
        "pred_ = np.asarray(pred_)\n",
        "test_values = np.asarray(test_values)\n",
        "\n",
        "mean_absolute_error(np.ndarray.flatten(pred_), np.ndarray.flatten(test_values))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}